{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b35536f6-166c-4b89-8136-96417db5be30",
   "metadata": {
    "id": "b35536f6-166c-4b89-8136-96417db5be30"
   },
   "source": [
    "<center><a href=\"https://www.nvidia.com/en-us/training/\"><img src=\"https://dli-lms.s3.amazonaws.com/assets/general/DLI_Header_White.png\" width=\"400\" height=\"186\" /></a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c8ac2e-eb68-4b84-85fe-3a6661eba976",
   "metadata": {
    "id": "77c8ac2e-eb68-4b84-85fe-3a6661eba976"
   },
   "source": [
    "<br>\n",
    "\n",
    "# <font color=\"#76b900\">**Notebook 8 [Assessment]:** RAG Evaluation</font>\n",
    "\n",
    "<br>\n",
    "\n",
    "Welcome to the last notebook of the course! In the previous notebook, you integrated a vector store solution into a RAG pipeline! In this notebook, you will take that same pipeline and evaluate it using numerical RAG evaluation techniques incorporating LLM-as-a-Judge metrics!\n",
    "\n",
    "<br>\n",
    "\n",
    "### **Learning Objectives:**\n",
    "\n",
    "- Learn how to integrate the techniques from prior notebooks to numerically approximate the goodness of your RAG pipeline.\n",
    "\n",
    "- **Final Exercice**: ***By working through this notebook in the Course Environment,* you will be able to submit the coding component of the course!**\n",
    "\n",
    "<br>\n",
    "\n",
    "### **Questions To Think About:**\n",
    "\n",
    "- As you go along, remember what our metrics actually represent. Should our pipeline pass these objectives? Is our judge LLM sufficient for evaluating the pipeline? Does a particular metric even matter for our use case?\n",
    "- If we left the vectorstore-as-a-memory component in our chain, do you think it would still pass the evaluation? Additionally, is the evaluation useful for assessing vectorstore-as-a-memory performance? \n",
    "\n",
    "<br>\n",
    "\n",
    "### **Environment Setup:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "w_A3rZOrIeQD",
   "metadata": {
    "id": "w_A3rZOrIeQD"
   },
   "outputs": [],
   "source": [
    "# %pip install -q langchain langchain-nvidia-ai-endpoints gradio rich\n",
    "# %pip install -q arxiv pymupdf faiss-cpu ragas\n",
    "\n",
    "## If you encounter a typing-extensions issue, restart your runtime and try again\n",
    "# from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "# ChatNVIDIA.get_available_models()\n",
    "\n",
    "from functools import partial\n",
    "from rich.console import Console\n",
    "from rich.style import Style\n",
    "from rich.theme import Theme\n",
    "\n",
    "console = Console()\n",
    "base_style = Style(color=\"#76B900\", bold=True)\n",
    "norm_style = Style(bold=True)\n",
    "pprint = partial(console.print, style=base_style)\n",
    "pprint2 = partial(console.print, style=norm_style)\n",
    "\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA, NVIDIAEmbeddings\n",
    "\n",
    "# NVIDIAEmbeddings.get_available_models()\n",
    "embedder = NVIDIAEmbeddings(model=\"nvidia/nv-embed-v1\", truncate=\"END\")\n",
    "\n",
    "# ChatNVIDIA.get_available_models(base_url=\"http://llm_client:9000/v1\")\n",
    "instruct_llm = ChatNVIDIA(model=\"meta/llama-3.1-8b-instruct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zEgV11oZmJGg",
   "metadata": {
    "id": "zEgV11oZmJGg"
   },
   "source": [
    "----\n",
    "\n",
    "<br>\n",
    "\n",
    "## **Part 1:** Pre-Release Evaluation\n",
    "\n",
    "In our previous notebook, we successfully combined several concepts to create a document chatbot with the aim of responsive and informative interactions. However, the diversity of user interactions necessitates comprehensive testing to truly understand the chatbot's performance. Thorough testing in varied scenarios is crucial to ensure that the system is not only robust and versatile but also aligns with user and provider expectations.\n",
    "\n",
    "After defining your chatbot's roles and implementing the necessary features, evaluating it becomes a multi-stage process:\n",
    "\n",
    "- **Typical Use Inspection:** Start by testing scenarios most relevant to your use case. See if your chatbot can reliably navigate discussions with limited human intervention.\n",
    "\n",
    "    - Additionally, identify limitations or compartments that should be redirected to a human for inspection/supervision (i.e., human swap-in to confirm transactions or perform sensitive navigation) and implement those options.\n",
    "\n",
    "- **Edge Case Inspection:** Explore the boundaries of typical use, identifying how the chatbot handles less common but plausible scenarios.\n",
    "\n",
    "    - Before any public release, assess critical boundary conditions that could pose liability risks, such as the potential generation of inappropriate content.\n",
    "\n",
    "    - Implement well-tested guardrails on all outputs (and possibly inputs) to limit undesired interactions and redirect users into predictable conversation flows.\n",
    "\n",
    "- **Progressive Rollout:** Rolling out your model to a limited audience (first internal, then [A/B](https://en.wikipedia.org/wiki/A/B_testing)) and implement analytics features like usage analytics dashboards and feedback avenues (flag/like/dislike/etc).\n",
    "\n",
    "Of these three steps, the first two can be done by a small team or an individual and should be iterated on as part of the development process. Unfortunately, this needs to be done frequently and can be prone to human error. **Luckily for us, LLMs can be used to help out with LLM-as-a-Judge formulations!**\n",
    "\n",
    "*(Yeah, this probably isn't surprising by now. LLMs being strong is why this course is here...).*\n",
    "\n",
    "----\n",
    "\n",
    "<br>\n",
    "\n",
    "## **Part 2:** LLM-as-a-Judge Formulation\n",
    "\n",
    "In the realm of conversational AI, using LLMs as evaluators or 'judges' has emerged as a useful approach for configurable automatic testing of natural language task performance:\n",
    "\n",
    "- An LLM can simulate a range of interaction scenarios and generate synthetic data, allowing an evaluation developer to generate targeted inputs to eliciting a range of behaviors from your chatbot.\n",
    "\n",
    "- The chatbot's correspondence/retrieval on the synthetic data can be evaluated or parsed by an LLM and a consistent output format such as \"Pass\"/\"Fail\", similarity, or extraction can be enforced.\n",
    "\n",
    "- Many such results can be aggregated and a metric can be derived which explains something like \"% of passing evaluations\", \"average number of relevant details from the sources\", \"average cosine similarity\", etc.\n",
    "\n",
    "This idea of using LLMs to test out and quantify chatbot quality, known as [**\"LLM-as-a-Judge,\"**](https://arxiv.org/abs/2306.05685) allows for easy test specifications that align closely with human judgment and can be fine-tuned and replicated at scale.\n",
    "\n",
    "**There are several popular frameworks for off-the-shelf judge formulations including:**\n",
    "- [**RAGAs (short for RAG Assessment)**](https://docs.ragas.io/en/stable/), which offers a suite of great starting points for your own evaluation efforts.\n",
    "- [**LangChain Evaluators**](https://python.langchain.com/v0.1/docs/guides/productionization/evaluation/), which are similar first-party options with many implicitly-constructible agents.\n",
    "\n",
    "Instead of using the chains as-is, we will instead expand on the ideas and evaluate our system with a more custom solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fDDNaBA9N3XM",
   "metadata": {
    "id": "fDDNaBA9N3XM"
   },
   "source": [
    "----\n",
    "\n",
    "<br>\n",
    "\n",
    "## **Part 3: [Assessment Prep]** Pairwise Evaluator\n",
    "\n",
    "The following exercise will flesh out a custom implementation of a simplified [LangChain Pairwise String Evaluator](https://python.langchain.com/v0.1/docs/guides/productionization/evaluation/comparison/pairwise_string/). \n",
    "\n",
    "**To prepare for our RAG chain evaluation, we will need to:**\n",
    "\n",
    "- Pull in our document index (the one we saved in the previous notebook).\n",
    "- Recreate our RAG pipeline of choice.\n",
    "\n",
    "**We will specifically be implementing a judge formulation with the following steps:**\n",
    "\n",
    "- Sample the RAG agent document pool to find two document chunks.\n",
    "- Use those two document chunks to generate a synthetic \"baseline\" question-answer pair.\n",
    "- Use the RAG agent to generate its own answer.\n",
    "- Use a judge LLM to compare the two responses while grounding the synthetic generation as \"ground-truth correct.\"\n",
    "\n",
    "**The chain should be a simple but powerful process that tests for the following objective:**\n",
    "\n",
    "> ***Does my RAG chain outperform a narrow chatbot with limited document access.***\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**This will be the system used for the final evaluation!** To see how this system is integrated into the autograder, please check out the implementation in [`frontend/server_app.py`](frontend/server_app.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bh8jaOqak0f",
   "metadata": {
    "id": "1bh8jaOqak0f"
   },
   "source": [
    "<br>\n",
    "\n",
    "### **Task 1:** Pull In Your Document Retrieval Index\n",
    "\n",
    "For this exercise, you will pull in the `docstore_index` file you created as part of your earlier notebook. The following cell should be able to load in the store as-is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "tlE7a2lseLOy",
   "metadata": {
    "id": "tlE7a2lseLOy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docstore_index/\n",
      "docstore_index/index.pkl\n",
      "docstore_index/index.faiss\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Constructed aggregate docstore with </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">181</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\"> chunks</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mConstructed aggregate docstore with \u001b[0m\u001b[1;36m181\u001b[0m\u001b[1;38;2;118;185;0m chunks\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Sample Chunk:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mSample Chunk:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paper: Toward Co-creative Dungeon Generation via Transfer Learning\n",
      "\n",
      "Summary: Co-creative Procedural Content Generation via Machine Learning (PCGML) refers to systems where a PCGML agent and a human work together to produce output content. One of the limitations of co-creative PCGML is that it requires co-creative training data for a PCGML agent to learn to interact with humans. However, acquiring this data is a difficult and time-consuming process. In this work, we propose approximating human-AI interaction data and employing transfer learning to adapt learned co-creative knowledge from one game to a different game. We explore this approach for co-creative Zelda dungeon room generation.\n",
      "\n",
      "Page Body: dimension is 10. Thus, we transfer only the first 10 of the 34 4x4\n",
      "filters in the first convolution layer. While thereâ€™s no guarantee that\n",
      "the first 10 filters will be the best 10 filters to transfer, we take this\n",
      "strategy throughout all layers with mismatched dimensions. Since\n",
      "our source domain and target domain have different design layouts,\n",
      "the knowledge the model will require will also differ. Therefore, all\n",
      "of the transferred weights are trainable.\n",
      "4.6\n",
      "Training\n",
      "The final step of our approach is to finetune the transferred weights\n",
      "on our approximated interaction data. We employ the adam opti-\n",
      "mizer as our optimizer due to the variance present in the original\n",
      "Zelda rooms. We set our batch size to 8 based on initial experiments.\n",
      "We also set our learning rate experimentally to 0.0001. For training\n",
      "time, we ran an exhaustive series of tests, training with each dataset\n",
      "from 1-20 epochs, and found that 15 epochs was ideal based on\n"
     ]
    }
   ],
   "source": [
    "## Make sure you have docstore_index.tgz in your working directory\n",
    "from langchain_nvidia_ai_endpoints import NVIDIAEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# embedder = NVIDIAEmbeddings(model=\"nvidia/embed-qa-4\", truncate=\"END\")\n",
    "\n",
    "!tar xzvf docstore_index.tgz\n",
    "docstore = FAISS.load_local(\"docstore_index\", embedder, allow_dangerous_deserialization=True)\n",
    "docs = list(docstore.docstore._dict.values())\n",
    "\n",
    "def format_chunk(doc):\n",
    "    return (\n",
    "        f\"Paper: {doc.metadata.get('Title', 'unknown')}\"\n",
    "        f\"\\n\\nSummary: {doc.metadata.get('Summary', 'unknown')}\"\n",
    "        f\"\\n\\nPage Body: {doc.page_content}\"\n",
    "    )\n",
    "\n",
    "## This printout just confirms that your store has been retrieved\n",
    "pprint(f\"Constructed aggregate docstore with {len(docstore.docstore._dict)} chunks\")\n",
    "pprint(f\"Sample Chunk:\")\n",
    "print(format_chunk(docs[len(docs)//2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dib0F-t2N4LJ",
   "metadata": {
    "id": "dib0F-t2N4LJ"
   },
   "source": [
    "<br>\n",
    "\n",
    "### **Task 2: [Exercise]** Pull In Your RAG Chain\n",
    "\n",
    "Now that we have our index, we can recreate the RAG agent from the previous notebook! \n",
    "\n",
    "**Key Modifications:**\n",
    "- To keep things simple, feel free to disregard the vectorstore-as-a-memory component. Incorporating it will require some more overhead and will make the exercise a bit more complicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "XBi6Y8b8aXd2",
   "metadata": {
    "id": "XBi6Y8b8aXd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did you know that there's a way to create entire video games, like Zelda dungeons, using machine learning? It's called co-creative procedural content generation, and it involves a human and a machine working together to create something entirely new. \n",
      "\n",
      "One interesting approach to this is using transfer learning, which allows us to take knowledge from one game and adapt it to another. This can be especially helpful when it comes to collecting interaction data, which is a crucial part of creating these co-creative systems. \n",
      "\n",
      "For example, a team of researchers proposed approximating human-AI interaction data and employing transfer learning to adapt learned co-creative knowledge from one game to a different game, like co-creative Zelda dungeon room generation [1]. They even explored strategies for approximating interaction data from non-interactive existing data. \n",
      "\n",
      "It's pretty mind-blowing to think about how machine learning can be used to create entire worlds and experiences. Who knows what kind of amazing things we'll be able to create with this technology in the future?"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnableBranch\n",
    "from langchain_core.runnables.passthrough import RunnableAssign\n",
    "from langchain.document_transformers import LongContextReorder\n",
    "\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA, NVIDIAEmbeddings\n",
    "\n",
    "from functools import partial\n",
    "from operator import itemgetter\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "#####################################################################\n",
    "\n",
    "# NVIDIAEmbeddings.get_available_models()\n",
    "embedder = NVIDIAEmbeddings(model=\"nvidia/nv-embed-v1\", truncate=\"END\")\n",
    "\n",
    "# ChatNVIDIA.get_available_models()\n",
    "instruct_llm = ChatNVIDIA(model=\"meta/llama-3.1-8b-instruct\")\n",
    "llm = instruct_llm | StrOutputParser()\n",
    "\n",
    "#####################################################################\n",
    "\n",
    "def docs2str(docs, title=\"Document\"):\n",
    "    \"\"\"Useful utility for making chunks into context string. Optional, but useful\"\"\"\n",
    "    out_str = \"\"\n",
    "    for doc in docs:\n",
    "        doc_name = getattr(doc, 'metadata', {}).get('Title', title)\n",
    "        if doc_name: out_str += f\"[Quote from {doc_name}] \"\n",
    "        out_str += getattr(doc, 'page_content', str(doc)) + \"\\n\"\n",
    "    return out_str\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_template(\n",
    "    \"You are a document chatbot. Help the user as they ask questions about documents.\"\n",
    "    \" User messaged just asked you a question: {input}\\n\\n\"\n",
    "    \" The following information may be useful for your response: \"\n",
    "    \" Document Retrieval:\\n{context}\\n\\n\"\n",
    "    \" (Answer only from retrieval. Only cite sources that are used. Make your response conversational)\"\n",
    "    \"\\n\\nUser Question: {input}\"\n",
    ")\n",
    "\n",
    "def output_puller(inputs):\n",
    "    \"\"\"\"Output generator. Useful if your chain returns a dictionary with key 'output'\"\"\"\n",
    "    if isinstance(inputs, dict):\n",
    "        inputs = [inputs]\n",
    "    for token in inputs:\n",
    "        if token.get('output'):\n",
    "            yield token.get('output')\n",
    "\n",
    "#####################################################################\n",
    "## TODO: Pull in your desired RAG Chain. Memory not necessary\n",
    "\n",
    "## Chain 1 Specs: \"Hello World\" -> retrieval_chain \n",
    "##   -> {'input': <str>, 'context' : <str>}\n",
    "long_reorder = RunnableLambda(LongContextReorder().transform_documents)  ## GIVEN\n",
    "\n",
    "context_getter = (\n",
    "    itemgetter(\"input\")\n",
    "    | docstore.as_retriever()\n",
    "    | long_reorder\n",
    "    | partial(docs2str, title=\"Document\")\n",
    ")\n",
    "\n",
    "retrieval_chain = (\n",
    "    {\"input\": (lambda x: x)}\n",
    "    | RunnableAssign({\"context\": context_getter})\n",
    ")\n",
    "\n",
    "## Chain 2 Specs: retrieval_chain -> generator_chain\n",
    "##   -> {\"output\" : <str>, ...} -> output_puller\n",
    "generator_chain = chat_prompt | llm\n",
    "generator_chain = {\"output\": generator_chain} | RunnableLambda(output_puller)  ## GIVEN\n",
    "\n",
    "## END TODO\n",
    "#####################################################################\n",
    "\n",
    "rag_chain = retrieval_chain | generator_chain\n",
    "\n",
    "# pprint(rag_chain.invoke(\"Tell me something interesting!\"))\n",
    "for token in rag_chain.stream(\"Tell me something interesting!\"):\n",
    "    print(token, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b880971-d3a0-433f-a60b-e8a4edb754c8",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### **Step 3:** Generating Synthetic Question-Answer Pairs\n",
    "\n",
    "In this section, we can implement the first few part of our evaluation routine:\n",
    "\n",
    "- **Sample the RAG agent document pool to find two document chunks.**\n",
    "- **Use those two document chunks to generate a synthetic \"baseline\" question-answer pair.**\n",
    "- Use the RAG agent to generate its own answer.\n",
    "- Use a judge LLM to compare the two responses while grounding the synthetic generation as \"ground-truth correct.\"\n",
    "\n",
    "The chain should be a simple but powerful process that tests for the following objective:\n",
    "\n",
    "> Does my RAG chain outperform a narrow chatbot with limited document access?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ymzuX-DSNvL6",
   "metadata": {
    "id": "ymzuX-DSNvL6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">QA Pair </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mQA Pair \u001b[0m\u001b[1;36m1\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Question: Can a co-creative procedural content generation system, which involves human-AI collaboration, be made </span>\n",
       "<span style=\"font-weight: bold\">more efficient and fair by utilizing a data generation method that produces unbiased and private data, such as the </span>\n",
       "<span style=\"font-weight: bold\">one proposed in the FFPDG paper?</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mQuestion: Can a co-creative procedural content generation system, which involves human-AI collaboration, be made \u001b[0m\n",
       "\u001b[1mmore efficient and fair by utilizing a data generation method that produces unbiased and private data, such as the \u001b[0m\n",
       "\u001b[1mone proposed in the FFPDG paper?\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Answer: Yes, it is possible to combine the co-creative procedural content generation system proposed in the Toward </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Co-creative Dungeon Generation via Transfer Learning paper with the data generation method from the FFPDG paper to </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">create a more efficient and fair system. The FFPDG paper proposes a method for generating fair and unbiased data </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">that can be used to train models, which could potentially be applied to the co-creative dungeon generation system. </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">This could help to address the limitations of co-creative PCGML, such as the difficulty of acquiring co-creative </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">training data, and improve the overall fairness and efficiency of the system.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mAnswer: Yes, it is possible to combine the co-creative procedural content generation system proposed in the Toward \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mCo-creative Dungeon Generation via Transfer Learning paper with the data generation method from the FFPDG paper to \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mcreate a more efficient and fair system. The FFPDG paper proposes a method for generating fair and unbiased data \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mthat can be used to train models, which could potentially be applied to the co-creative dungeon generation system. \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mThis could help to address the limitations of co-creative PCGML, such as the difficulty of acquiring co-creative \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mtraining data, and improve the overall fairness and efficiency of the system.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">QA Pair </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mQA Pair \u001b[0m\u001b[1;36m2\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Question: Can strong large language models (LLMs) like GPT-</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\"> be used effectively as judges to evaluate other LLMs </span>\n",
       "<span style=\"font-weight: bold\">on open-ended questions, and what level of agreement can they achieve with human preferences?</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mQuestion: Can strong large language models \u001b[0m\u001b[1m(\u001b[0m\u001b[1mLLMs\u001b[0m\u001b[1m)\u001b[0m\u001b[1m like GPT-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1m be used effectively as judges to evaluate other LLMs \u001b[0m\n",
       "\u001b[1mon open-ended questions, and what level of agreement can they achieve with human preferences?\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Answer: Yes, strong LLMs like GPT-</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\"> can be used effectively as judges, achieving over </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">80</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">% agreement with both </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">controlled and crowdsourced human preferences, according to the results of the study presented in the paper </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mAnswer: Yes, strong LLMs like GPT-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;38;2;118;185;0m can be used effectively as judges, achieving over \u001b[0m\u001b[1;36m80\u001b[0m\u001b[1;38;2;118;185;0m% agreement with both \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mcontrolled and crowdsourced human preferences, according to the results of the study presented in the paper \u001b[0m\n",
       "\u001b[32m\"Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena\"\u001b[0m\u001b[1;38;2;118;185;0m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">QA Pair </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mQA Pair \u001b[0m\u001b[1;36m3\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Question: How can we develop high-quality co-creative agents for procedural content generation in games without </span>\n",
       "<span style=\"font-weight: bold\">requiring game-specific user studies, especially when acquiring such data is difficult and time-consuming?</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mQuestion: How can we develop high-quality co-creative agents for procedural content generation in games without \u001b[0m\n",
       "\u001b[1mrequiring game-specific user studies, especially when acquiring such data is difficult and time-consuming?\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Answer: We can approximate human-AI interaction data and employ transfer learning to adapt learned co-creative </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">knowledge from one game to a different game, as proposed in the approach for co-creative Zelda dungeon room </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">generation.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mAnswer: We can approximate human-AI interaction data and employ transfer learning to adapt learned co-creative \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mknowledge from one game to a different game, as proposed in the approach for co-creative Zelda dungeon room \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mgeneration.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "num_questions = 3\n",
    "synth_questions = []\n",
    "synth_answers = []\n",
    "\n",
    "simple_prompt = ChatPromptTemplate.from_messages([('system', '{system}'), ('user', 'INPUT: {input}')])\n",
    "\n",
    "for i in range(num_questions):\n",
    "    doc1, doc2 = random.sample(docs, 2)\n",
    "    sys_msg = (\n",
    "        \"Use the documents provided by the user to generate an interesting question-answer pair.\"\n",
    "        \" Try to use both documents if possible, and rely more on the document bodies than the summary.\"\n",
    "        \" Use the format:\\nQuestion: (good question, 1-3 sentences, detailed)\\n\\nAnswer: (answer derived from the documents)\"\n",
    "        \" DO NOT SAY: \\\"Here is an interesting question pair\\\" or similar. FOLLOW FORMAT!\"\n",
    "    )\n",
    "    usr_msg = (\n",
    "        f\"Document1: {format_chunk(doc1)}\\n\\n\"\n",
    "        f\"Document2: {format_chunk(doc2)}\"\n",
    "    )\n",
    "\n",
    "    qa_pair = (simple_prompt | llm).invoke({'system': sys_msg, 'input': usr_msg})\n",
    "    synth_questions += [qa_pair.split('\\n\\n')[0]]\n",
    "    synth_answers += [qa_pair.split('\\n\\n')[1]]\n",
    "    pprint2(f\"QA Pair {i+1}\")\n",
    "    pprint2(synth_questions[-1])\n",
    "    pprint(synth_answers[-1])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5Q-3X4vS98P",
   "metadata": {
    "id": "c5Q-3X4vS98P"
   },
   "source": [
    "<br>\n",
    "\n",
    "### **Step 4:** Answer The Synthetic Questions\n",
    "\n",
    "In this section, we can implement the third part of our evaluation routine:\n",
    "\n",
    "- Sample the RAG agent document pool to find two document chunks.\n",
    "- Use those two document chunks to generate a synthetic \"baseline\" question-answer pair.\n",
    "- **Use the RAG agent to generate its own answer.**\n",
    "- Use a judge LLM to compare the two responses while grounding the synthetic generation as \"ground-truth correct.\"\n",
    "\n",
    "The chain should be a simple but powerful process that tests for the following objective:\n",
    "\n",
    "> Does my RAG chain outperform a narrow chatbot with limited document access?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7T3GSwhZPHjF",
   "metadata": {
    "id": "7T3GSwhZPHjF"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">QA Pair </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "<span style=\"font-weight: bold\">Question: Can a co-creative procedural content generation system, which involves human-AI collaboration, be made </span>\n",
       "<span style=\"font-weight: bold\">more efficient and fair by utilizing a data generation method that produces unbiased and private data, such as the </span>\n",
       "<span style=\"font-weight: bold\">one proposed in the FFPDG paper?</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mQA Pair \u001b[0m\u001b[1;36m1\u001b[0m\n",
       "\u001b[1mQuestion: Can a co-creative procedural content generation system, which involves human-AI collaboration, be made \u001b[0m\n",
       "\u001b[1mmore efficient and fair by utilizing a data generation method that produces unbiased and private data, such as the \u001b[0m\n",
       "\u001b[1mone proposed in the FFPDG paper?\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">RAG Answer: So, the question is whether a co-creative procedural content generation system can benefit from a data </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">generation method like FFPDG. </span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">According to the FFPDG paper, their proposed method is indeed fast, fair, and private. They claim that their </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">algorithm can generate fair and unbiased data, which is robust to membership inference attacks and preserves </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">individual/group fairness. This sounds promising for a co-creative system where human-AI collaboration is key.</span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">The FFPDG paper also mentions that their method is differentially private under certain conditions, which could be </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">beneficial for maintaining user privacy in a co-creative system. Moreover, their algorithm is said to be more </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">computationally efficient than GAN-based methods, which could be a significant advantage in terms of scalability.</span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">However, it's worth noting that the FFPDG paper does mention some limitations, such as the need to scale the </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">algorithm to high-dimensional datasets and improve the processing of categorical features. Additionally, they </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">suggest merging fair processing and private data generation into one step, which could be an interesting area of </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">future research.</span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Overall, it seems like the FFPDG paper proposes a promising approach for generating unbiased and private data, </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">which could be beneficial for a co-creative procedural content generation system.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mRAG Answer: So, the question is whether a co-creative procedural content generation system can benefit from a data \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mgeneration method like FFPDG. \u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0mAccording to the FFPDG paper, their proposed method is indeed fast, fair, and private. They claim that their \u001b[0m\n",
       "\u001b[1;38;2;118;185;0malgorithm can generate fair and unbiased data, which is robust to membership inference attacks and preserves \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mindividual/group fairness. This sounds promising for a co-creative system where human-AI collaboration is key.\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0mThe FFPDG paper also mentions that their method is differentially private under certain conditions, which could be \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mbeneficial for maintaining user privacy in a co-creative system. Moreover, their algorithm is said to be more \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mcomputationally efficient than GAN-based methods, which could be a significant advantage in terms of scalability.\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0mHowever, it's worth noting that the FFPDG paper does mention some limitations, such as the need to scale the \u001b[0m\n",
       "\u001b[1;38;2;118;185;0malgorithm to high-dimensional datasets and improve the processing of categorical features. Additionally, they \u001b[0m\n",
       "\u001b[1;38;2;118;185;0msuggest merging fair processing and private data generation into one step, which could be an interesting area of \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mfuture research.\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0mOverall, it seems like the FFPDG paper proposes a promising approach for generating unbiased and private data, \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mwhich could be beneficial for a co-creative procedural content generation system.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">QA Pair </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
       "<span style=\"font-weight: bold\">Question: Can strong large language models (LLMs) like GPT-</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\"> be used effectively as judges to evaluate other LLMs </span>\n",
       "<span style=\"font-weight: bold\">on open-ended questions, and what level of agreement can they achieve with human preferences?</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mQA Pair \u001b[0m\u001b[1;36m2\u001b[0m\n",
       "\u001b[1mQuestion: Can strong large language models \u001b[0m\u001b[1m(\u001b[0m\u001b[1mLLMs\u001b[0m\u001b[1m)\u001b[0m\u001b[1m like GPT-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1m be used effectively as judges to evaluate other LLMs \u001b[0m\n",
       "\u001b[1mon open-ended questions, and what level of agreement can they achieve with human preferences?\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">RAG Answer: Based on the provided information, it seems like strong LLMs like GPT-</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\"> can indeed be used effectively </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">as judges to evaluate other LLMs on open-ended questions. According to the paper </span><span style=\"color: #008000; text-decoration-color: #008000\">'Judging LLM-as-a-Judge with </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">MT-Bench and Chatbot Arena'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">, LLM-as-a-judge is a scalable and explainable way to approximate human preferences. </span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">In fact, the authors of the paper even explored using GPT-</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\"> as a judge to evaluate other LLMs and found that it can</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">match both controlled and crowdsourced human preferences well, achieving over </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">80</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">% agreement. This level of </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">agreement is also comparable to the agreement between humans, which is quite impressive. </span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">It's worth noting that the authors also propose solutions to mitigate some of the limitations and biases of using </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">LLMs as judges, such as position, verbosity, and self-enhancement biases, as well as limited reasoning ability. </span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Overall, the results suggest that strong LLMs like GPT-</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\"> can be a reliable and efficient way to evaluate other LLMs</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">on open-ended questions, and their agreement with human preferences is quite high.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mRAG Answer: Based on the provided information, it seems like strong LLMs like GPT-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;38;2;118;185;0m can indeed be used effectively \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mas judges to evaluate other LLMs on open-ended questions. According to the paper \u001b[0m\u001b[32m'Judging LLM-as-a-Judge with \u001b[0m\n",
       "\u001b[32mMT-Bench and Chatbot Arena'\u001b[0m\u001b[1;38;2;118;185;0m, LLM-as-a-judge is a scalable and explainable way to approximate human preferences. \u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0mIn fact, the authors of the paper even explored using GPT-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;38;2;118;185;0m as a judge to evaluate other LLMs and found that it can\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mmatch both controlled and crowdsourced human preferences well, achieving over \u001b[0m\u001b[1;36m80\u001b[0m\u001b[1;38;2;118;185;0m% agreement. This level of \u001b[0m\n",
       "\u001b[1;38;2;118;185;0magreement is also comparable to the agreement between humans, which is quite impressive. \u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0mIt's worth noting that the authors also propose solutions to mitigate some of the limitations and biases of using \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mLLMs as judges, such as position, verbosity, and self-enhancement biases, as well as limited reasoning ability. \u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0mOverall, the results suggest that strong LLMs like GPT-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;38;2;118;185;0m can be a reliable and efficient way to evaluate other LLMs\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mon open-ended questions, and their agreement with human preferences is quite high.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">QA Pair </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>\n",
       "<span style=\"font-weight: bold\">Question: How can we develop high-quality co-creative agents for procedural content generation in games without </span>\n",
       "<span style=\"font-weight: bold\">requiring game-specific user studies, especially when acquiring such data is difficult and time-consuming?</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mQA Pair \u001b[0m\u001b[1;36m3\u001b[0m\n",
       "\u001b[1mQuestion: How can we develop high-quality co-creative agents for procedural content generation in games without \u001b[0m\n",
       "\u001b[1mrequiring game-specific user studies, especially when acquiring such data is difficult and time-consuming?\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">RAG Answer: To develop high-quality co-creative agents for procedural content generation in games without requiring</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">game-specific user studies, researchers have proposed using transfer learning. This involves transferring machine </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">learned knowledge from a source game model trained on interaction data to a target game model. </span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">The key idea is that while acquiring interaction data for a specific game can be time-consuming, it's possible to </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">reuse machine learned knowledge from one source game domain for a different target game domain. This approach can </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">help overcome the limitation of co-creative procedural content generation via machine learning (PCGML) requiring </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">co-creative training data for a PCGML agent to learn to interact with humans.</span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">In fact, a study by Zhou and Guzdial (</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2021</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">) [</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">] demonstrated the feasibility of using transfer learning to adapt </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">machine learned knowledge from one game to a different game. They proposed three methods to approximate interaction</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">data from non-interactive data and showed that by fine-tuning the source domain model, it's possible to positively </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">inherit some knowledge.</span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">This approach can help reduce the need for game-specific user studies, making it more feasible to develop </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">high-quality co-creative agents for procedural content generation in games. </span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Reference:</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">] Zhou, Z., &amp; Guzdial, M. (</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2021</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">). Toward Co-creative Dungeon Generation via Transfer Learning. In FDG'</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\"> (pp. </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">-</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">).</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mRAG Answer: To develop high-quality co-creative agents for procedural content generation in games without requiring\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mgame-specific user studies, researchers have proposed using transfer learning. This involves transferring machine \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mlearned knowledge from a source game model trained on interaction data to a target game model. \u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0mThe key idea is that while acquiring interaction data for a specific game can be time-consuming, it's possible to \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mreuse machine learned knowledge from one source game domain for a different target game domain. This approach can \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mhelp overcome the limitation of co-creative procedural content generation via machine learning \u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\u001b[1;38;2;118;185;0mPCGML\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m requiring \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mco-creative training data for a PCGML agent to learn to interact with humans.\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0mIn fact, a study by Zhou and Guzdial \u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\u001b[1;36m2021\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m \u001b[0m\u001b[1;38;2;118;185;0m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;38;2;118;185;0m]\u001b[0m\u001b[1;38;2;118;185;0m demonstrated the feasibility of using transfer learning to adapt \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mmachine learned knowledge from one game to a different game. They proposed three methods to approximate interaction\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mdata from non-interactive data and showed that by fine-tuning the source domain model, it's possible to positively \u001b[0m\n",
       "\u001b[1;38;2;118;185;0minherit some knowledge.\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0mThis approach can help reduce the need for game-specific user studies, making it more feasible to develop \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mhigh-quality co-creative agents for procedural content generation in games. \u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0mReference:\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;38;2;118;185;0m]\u001b[0m\u001b[1;38;2;118;185;0m Zhou, Z., & Guzdial, M. \u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\u001b[1;36m2021\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m. Toward Co-creative Dungeon Generation via Transfer Learning. In FDG'\u001b[0m\u001b[1;36m21\u001b[0m\u001b[1;38;2;118;185;0m \u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\u001b[1;38;2;118;185;0mpp. \u001b[0m\n",
       "\u001b[1;36m1\u001b[0m\u001b[1;38;2;118;185;0m-\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## TODO: Generate some synthetic answers to the questions above.\n",
    "##   Try to use the same syntax as the cell above\n",
    "rag_answers = []\n",
    "for i, q in enumerate(synth_questions):\n",
    "\n",
    "    ## Compute the RAG Answer\n",
    "    ## Note: synth_questions entries are \"Question: ...\", so pass the full string through for consistency\n",
    "    rag_answer = \"\".join([tok for tok in rag_chain.stream(q)]).strip()\n",
    "\n",
    "    rag_answers += [rag_answer]\n",
    "    pprint2(f\"QA Pair {i+1}\", q, \"\", sep=\"\\n\")\n",
    "    pprint(f\"RAG Answer: {rag_answer}\", \"\", sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ho5cnN_Xt_yr",
   "metadata": {
    "id": "Ho5cnN_Xt_yr"
   },
   "source": [
    "<br>\n",
    "\n",
    "### **Step 5:** Implement A Human Preference Metric\n",
    "\n",
    "In this section, we can implement the fourth part of our evaluation routine:\n",
    "\n",
    "- Sample the RAG agent document pool to find two document chunks.\n",
    "- Use those two document chunks to generate a synthetic \"baseline\" question-answer pair.\n",
    "- Use the RAG agent to generate its own answer.\n",
    "- **Use a judge LLM to compare the two responses while grounding the synthetic generation as \"ground-truth correct.\"**\n",
    "\n",
    "The chain should be a simple but powerful process that tests for the following objective:\n",
    "\n",
    "> Does my RAG chain outperform a narrow chatbot with limited document access?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sf6f2oFLuPtu",
   "metadata": {
    "id": "sf6f2oFLuPtu"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Set </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "\n",
       "<span style=\"font-weight: bold\">Question: Question: Can a co-creative procedural content generation system, which involves human-AI collaboration, </span>\n",
       "<span style=\"font-weight: bold\">be made more efficient and fair by utilizing a data generation method that produces unbiased and private data, such</span>\n",
       "<span style=\"font-weight: bold\">as the one proposed in the FFPDG paper?</span>\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mSet \u001b[0m\u001b[1;36m1\u001b[0m\n",
       "\n",
       "\u001b[1mQuestion: Question: Can a co-creative procedural content generation system, which involves human-AI collaboration, \u001b[0m\n",
       "\u001b[1mbe made more efficient and fair by utilizing a data generation method that produces unbiased and private data, such\u001b[0m\n",
       "\u001b[1mas the one proposed in the FFPDG paper?\u001b[0m\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Synth Answer: Answer: Yes, it is possible to combine the co-creative procedural content generation system proposed </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">in the Toward Co-creative Dungeon Generation via Transfer Learning paper with the data generation method from the </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">FFPDG paper to create a more efficient and fair system. The FFPDG paper proposes a method for generating fair and </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">unbiased data that can be used to train models, which could potentially be applied to the co-creative dungeon </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">generation system. This could help to address the limitations of co-creative PCGML, such as the difficulty of </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">acquiring co-creative training data, and improve the overall fairness and efficiency of the system.</span>\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mSynth Answer: Answer: Yes, it is possible to combine the co-creative procedural content generation system proposed \u001b[0m\n",
       "\u001b[1;38;2;118;185;0min the Toward Co-creative Dungeon Generation via Transfer Learning paper with the data generation method from the \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mFFPDG paper to create a more efficient and fair system. The FFPDG paper proposes a method for generating fair and \u001b[0m\n",
       "\u001b[1;38;2;118;185;0munbiased data that can be used to train models, which could potentially be applied to the co-creative dungeon \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mgeneration system. This could help to address the limitations of co-creative PCGML, such as the difficulty of \u001b[0m\n",
       "\u001b[1;38;2;118;185;0macquiring co-creative training data, and improve the overall fairness and efficiency of the system.\u001b[0m\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">RAG Answer: So, the question is whether a co-creative procedural content generation system can benefit from a data </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">generation method like FFPDG. </span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">According to the FFPDG paper, their proposed method is indeed fast, fair, and private. They claim that their </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">algorithm can generate fair and unbiased data, which is robust to membership inference attacks and preserves </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">individual/group fairness. This sounds promising for a co-creative system where human-AI collaboration is key.</span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">The FFPDG paper also mentions that their method is differentially private under certain conditions, which could be </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">beneficial for maintaining user privacy in a co-creative system. Moreover, their algorithm is said to be more </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">computationally efficient than GAN-based methods, which could be a significant advantage in terms of scalability.</span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">However, it's worth noting that the FFPDG paper does mention some limitations, such as the need to scale the </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">algorithm to high-dimensional datasets and improve the processing of categorical features. Additionally, they </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">suggest merging fair processing and private data generation into one step, which could be an interesting area of </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">future research.</span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Overall, it seems like the FFPDG paper proposes a promising approach for generating unbiased and private data, </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">which could be beneficial for a co-creative procedural content generation system.</span>\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mRAG Answer: So, the question is whether a co-creative procedural content generation system can benefit from a data \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mgeneration method like FFPDG. \u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0mAccording to the FFPDG paper, their proposed method is indeed fast, fair, and private. They claim that their \u001b[0m\n",
       "\u001b[1;38;2;118;185;0malgorithm can generate fair and unbiased data, which is robust to membership inference attacks and preserves \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mindividual/group fairness. This sounds promising for a co-creative system where human-AI collaboration is key.\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0mThe FFPDG paper also mentions that their method is differentially private under certain conditions, which could be \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mbeneficial for maintaining user privacy in a co-creative system. Moreover, their algorithm is said to be more \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mcomputationally efficient than GAN-based methods, which could be a significant advantage in terms of scalability.\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0mHowever, it's worth noting that the FFPDG paper does mention some limitations, such as the need to scale the \u001b[0m\n",
       "\u001b[1;38;2;118;185;0malgorithm to high-dimensional datasets and improve the processing of categorical features. Additionally, they \u001b[0m\n",
       "\u001b[1;38;2;118;185;0msuggest merging fair processing and private data generation into one step, which could be an interesting area of \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mfuture research.\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0mOverall, it seems like the FFPDG paper proposes a promising approach for generating unbiased and private data, \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mwhich could be beneficial for a co-creative procedural content generation system.\u001b[0m\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Synth Evaluation: [</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">] The second answer provides more specific details and analysis of the FFPDG paper, addressing </span>\n",
       "<span style=\"font-weight: bold\">potential limitations and benefits for the co-creative system.</span>\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mSynth Evaluation: \u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m\u001b[1m The second answer provides more specific details and analysis of the FFPDG paper, addressing \u001b[0m\n",
       "\u001b[1mpotential limitations and benefits for the co-creative system.\u001b[0m\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Set </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
       "\n",
       "<span style=\"font-weight: bold\">Question: Question: Can strong large language models (LLMs) like GPT-</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\"> be used effectively as judges to evaluate </span>\n",
       "<span style=\"font-weight: bold\">other LLMs on open-ended questions, and what level of agreement can they achieve with human preferences?</span>\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mSet \u001b[0m\u001b[1;36m2\u001b[0m\n",
       "\n",
       "\u001b[1mQuestion: Question: Can strong large language models \u001b[0m\u001b[1m(\u001b[0m\u001b[1mLLMs\u001b[0m\u001b[1m)\u001b[0m\u001b[1m like GPT-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1m be used effectively as judges to evaluate \u001b[0m\n",
       "\u001b[1mother LLMs on open-ended questions, and what level of agreement can they achieve with human preferences?\u001b[0m\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Synth Answer: Answer: Yes, strong LLMs like GPT-</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\"> can be used effectively as judges, achieving over </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">80</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">% agreement </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">with both controlled and crowdsourced human preferences, according to the results of the study presented in the </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">paper </span><span style=\"color: #008000; text-decoration-color: #008000\">\"Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena\"</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">.</span>\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mSynth Answer: Answer: Yes, strong LLMs like GPT-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;38;2;118;185;0m can be used effectively as judges, achieving over \u001b[0m\u001b[1;36m80\u001b[0m\u001b[1;38;2;118;185;0m% agreement \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mwith both controlled and crowdsourced human preferences, according to the results of the study presented in the \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mpaper \u001b[0m\u001b[32m\"Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena\"\u001b[0m\u001b[1;38;2;118;185;0m.\u001b[0m\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">RAG Answer: Based on the provided information, it seems like strong LLMs like GPT-</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\"> can indeed be used effectively </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">as judges to evaluate other LLMs on open-ended questions. According to the paper </span><span style=\"color: #008000; text-decoration-color: #008000\">'Judging LLM-as-a-Judge with </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">MT-Bench and Chatbot Arena'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">, LLM-as-a-judge is a scalable and explainable way to approximate human preferences. </span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">In fact, the authors of the paper even explored using GPT-</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\"> as a judge to evaluate other LLMs and found that it can</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">match both controlled and crowdsourced human preferences well, achieving over </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">80</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">% agreement. This level of </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">agreement is also comparable to the agreement between humans, which is quite impressive. </span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">It's worth noting that the authors also propose solutions to mitigate some of the limitations and biases of using </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">LLMs as judges, such as position, verbosity, and self-enhancement biases, as well as limited reasoning ability. </span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Overall, the results suggest that strong LLMs like GPT-</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\"> can be a reliable and efficient way to evaluate other LLMs</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">on open-ended questions, and their agreement with human preferences is quite high.</span>\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mRAG Answer: Based on the provided information, it seems like strong LLMs like GPT-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;38;2;118;185;0m can indeed be used effectively \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mas judges to evaluate other LLMs on open-ended questions. According to the paper \u001b[0m\u001b[32m'Judging LLM-as-a-Judge with \u001b[0m\n",
       "\u001b[32mMT-Bench and Chatbot Arena'\u001b[0m\u001b[1;38;2;118;185;0m, LLM-as-a-judge is a scalable and explainable way to approximate human preferences. \u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0mIn fact, the authors of the paper even explored using GPT-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;38;2;118;185;0m as a judge to evaluate other LLMs and found that it can\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mmatch both controlled and crowdsourced human preferences well, achieving over \u001b[0m\u001b[1;36m80\u001b[0m\u001b[1;38;2;118;185;0m% agreement. This level of \u001b[0m\n",
       "\u001b[1;38;2;118;185;0magreement is also comparable to the agreement between humans, which is quite impressive. \u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0mIt's worth noting that the authors also propose solutions to mitigate some of the limitations and biases of using \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mLLMs as judges, such as position, verbosity, and self-enhancement biases, as well as limited reasoning ability. \u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0mOverall, the results suggest that strong LLMs like GPT-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;38;2;118;185;0m can be a reliable and efficient way to evaluate other LLMs\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mon open-ended questions, and their agreement with human preferences is quite high.\u001b[0m\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Synth Evaluation: [</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">] Answer </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\"> is nearly identical to Answer </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">, providing a more detailed explanation but not </span>\n",
       "<span style=\"font-weight: bold\">introducing any inconsistencies.</span>\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mSynth Evaluation: \u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m\u001b[1m Answer \u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m is nearly identical to Answer \u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m, providing a more detailed explanation but not \u001b[0m\n",
       "\u001b[1mintroducing any inconsistencies.\u001b[0m\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Set </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>\n",
       "\n",
       "<span style=\"font-weight: bold\">Question: Question: How can we develop high-quality co-creative agents for procedural content generation in games </span>\n",
       "<span style=\"font-weight: bold\">without requiring game-specific user studies, especially when acquiring such data is difficult and time-consuming?</span>\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mSet \u001b[0m\u001b[1;36m3\u001b[0m\n",
       "\n",
       "\u001b[1mQuestion: Question: How can we develop high-quality co-creative agents for procedural content generation in games \u001b[0m\n",
       "\u001b[1mwithout requiring game-specific user studies, especially when acquiring such data is difficult and time-consuming?\u001b[0m\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Synth Answer: Answer: We can approximate human-AI interaction data and employ transfer learning to adapt learned </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">co-creative knowledge from one game to a different game, as proposed in the approach for co-creative Zelda dungeon </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">room generation.</span>\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mSynth Answer: Answer: We can approximate human-AI interaction data and employ transfer learning to adapt learned \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mco-creative knowledge from one game to a different game, as proposed in the approach for co-creative Zelda dungeon \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mroom generation.\u001b[0m\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">RAG Answer: To develop high-quality co-creative agents for procedural content generation in games without requiring</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">game-specific user studies, researchers have proposed using transfer learning. This involves transferring machine </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">learned knowledge from a source game model trained on interaction data to a target game model. </span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">The key idea is that while acquiring interaction data for a specific game can be time-consuming, it's possible to </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">reuse machine learned knowledge from one source game domain for a different target game domain. This approach can </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">help overcome the limitation of co-creative procedural content generation via machine learning (PCGML) requiring </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">co-creative training data for a PCGML agent to learn to interact with humans.</span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">In fact, a study by Zhou and Guzdial (</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2021</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">) [</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">] demonstrated the feasibility of using transfer learning to adapt </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">machine learned knowledge from one game to a different game. They proposed three methods to approximate interaction</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">data from non-interactive data and showed that by fine-tuning the source domain model, it's possible to positively </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">inherit some knowledge.</span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">This approach can help reduce the need for game-specific user studies, making it more feasible to develop </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">high-quality co-creative agents for procedural content generation in games. </span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Reference:</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">] Zhou, Z., &amp; Guzdial, M. (</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2021</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">). Toward Co-creative Dungeon Generation via Transfer Learning. In FDG'</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\"> (pp. </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">-</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">).</span>\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mRAG Answer: To develop high-quality co-creative agents for procedural content generation in games without requiring\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mgame-specific user studies, researchers have proposed using transfer learning. This involves transferring machine \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mlearned knowledge from a source game model trained on interaction data to a target game model. \u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0mThe key idea is that while acquiring interaction data for a specific game can be time-consuming, it's possible to \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mreuse machine learned knowledge from one source game domain for a different target game domain. This approach can \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mhelp overcome the limitation of co-creative procedural content generation via machine learning \u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\u001b[1;38;2;118;185;0mPCGML\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m requiring \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mco-creative training data for a PCGML agent to learn to interact with humans.\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0mIn fact, a study by Zhou and Guzdial \u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\u001b[1;36m2021\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m \u001b[0m\u001b[1;38;2;118;185;0m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;38;2;118;185;0m]\u001b[0m\u001b[1;38;2;118;185;0m demonstrated the feasibility of using transfer learning to adapt \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mmachine learned knowledge from one game to a different game. They proposed three methods to approximate interaction\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mdata from non-interactive data and showed that by fine-tuning the source domain model, it's possible to positively \u001b[0m\n",
       "\u001b[1;38;2;118;185;0minherit some knowledge.\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0mThis approach can help reduce the need for game-specific user studies, making it more feasible to develop \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mhigh-quality co-creative agents for procedural content generation in games. \u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0mReference:\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;38;2;118;185;0m]\u001b[0m\u001b[1;38;2;118;185;0m Zhou, Z., & Guzdial, M. \u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\u001b[1;36m2021\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m. Toward Co-creative Dungeon Generation via Transfer Learning. In FDG'\u001b[0m\u001b[1;36m21\u001b[0m\u001b[1;38;2;118;185;0m \u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\u001b[1;38;2;118;185;0mpp. \u001b[0m\n",
       "\u001b[1;36m1\u001b[0m\u001b[1;38;2;118;185;0m-\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m.\u001b[0m\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Synth Evaluation: [</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">] The new answer provides a detailed explanation, references a relevant study, and offers </span>\n",
       "<span style=\"font-weight: bold\">specific methods to approximate interaction data, making it more comprehensive and reliable than the ground truth.</span>\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mSynth Evaluation: \u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m\u001b[1m The new answer provides a detailed explanation, references a relevant study, and offers \u001b[0m\n",
       "\u001b[1mspecific methods to approximate interaction data, making it more comprehensive and reliable than the ground truth.\u001b[0m\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## TODO: Adapt this prompt for whichever LLM you're actually interested in using. \n",
    "## If it's llama, maybe system message would be good?\n",
    "eval_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are a strict evaluator.\\n\"\n",
    "     \"You must choose exactly one of the two labels:\\n\"\n",
    "     \"[1] Answer 2 is worse than Answer 1, does not answer, or introduces inconsistencies.\\n\"\n",
    "     \"[2] Answer 2 is better than Answer 1 and does not introduce inconsistencies.\\n\\n\"\n",
    "     \"Output format MUST be exactly:\\n\"\n",
    "     \"[1] <one short justification>\\n\"\n",
    "     \"or\\n\"\n",
    "     \"[2] <one short justification>\\n\\n\"\n",
    "     \"Do not add any other text.\"),\n",
    "    (\"user\", \"{qa_trio}\")\n",
    "])\n",
    "\n",
    "pref_score = []\n",
    "\n",
    "trio_gen = zip(synth_questions, synth_answers, rag_answers)\n",
    "for i, (q, a_synth, a_rag) in enumerate(trio_gen):\n",
    "    pprint2(f\"Set {i+1}\\n\\nQuestion: {q}\\n\\n\")\n",
    "\n",
    "    qa_trio = f\"Question: {q}\\n\\nAnswer 1 (Ground Truth): {a_synth}\\n\\n Answer 2 (New Answer): {a_rag}\"\n",
    "    pref_score += [(eval_prompt | llm).invoke({'qa_trio': qa_trio})]\n",
    "    pprint(f\"Synth Answer: {a_synth}\\n\\n\")\n",
    "    pprint(f\"RAG Answer: {a_rag}\\n\\n\")\n",
    "    pprint2(f\"Synth Evaluation: {pref_score[-1]}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6595662-9f49-44eb-9868-2a3fdb1fb60f",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Congratulations! We now have an LLM system that reasons about our pipeline and tries to evaluate it!** Now that we have some judge results, we can simply aggregate the results and see how often our formulation was according to an LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3L_q6fMH3i6_",
   "metadata": {
    "id": "3L_q6fMH3i6_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preference Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "pref_score = sum((\"[2]\" in score) for score in pref_score) / len(pref_score)\n",
    "print(f\"Preference Score: {pref_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf80bf04-118d-44a2-a740-361a756a1d5f",
   "metadata": {
    "id": "cf80bf04-118d-44a2-a740-361a756a1d5f"
   },
   "source": [
    "----\n",
    "\n",
    "<br>\n",
    "\n",
    "## **Part 4:** Advanced Formulations\n",
    "\n",
    "The exercise above was meant to prepare you for the final assessment of the course and showcased a simple but effective evaluator chain. The objective and implementation details were provided for you, and the logic for using it probably makes sense now that you've seen it in action. \n",
    "\n",
    "With that being said, this metric was merely a product of us specifying:\n",
    "- **What kind of behavior is important for our pipeline to have?**\n",
    "- **What do we need to do in order to exhibit and evaluate this behavior?**\n",
    "\n",
    "From these two questions, we could have come up with plenty of other evaluation metrics that could have assessed different attributes, incorporated different evaluator chain techniques, and even required different pipeline organization strategies. Though far from an exhaustive list, some common formulations you will likely come across may include:\n",
    "\n",
    "- **Style Evaluation:** Some evaluation formulations can be as simple as \"let me ask some questions and see if the output feels desirable.\" This might be used to see whether a chatbot \"acts like it's supposed to\" based on a description provided to a judge LLM. We're using quotations since this kind of assessment can reasonably be achieved with nothing but prompt engineering and a while loop.\n",
    "\n",
    "- **Ground-Truth Evaluation:** In our chain, we used synthetic generation to create some random questions and answers using a sampling strategy, but in reality you may actually have some representative questions and answers that you need your chatbot to consistently get right! In this case, a modification of the exercise chain above should be implemented and closely monitored as you develop your pipelines.\n",
    "\n",
    "- **Retrieval/Augmentation Evaluation:** This course made many assumptions about what kinds of preprocessing and prompting steps would be good for your pipelines, and much of this was determined by experimentation. Factors such as document preprocessing, chunking strategies, model selection, and prompt specification all played important roles, so creating metrics to validate these decisions may be of interest. This kind of metric might require your pipeline to output your context chunks or may even rely solely on embedding similarity comparisons, so keep this in mind when trying to implement a chain that works with multiple evaluation strategies. Consider the [**RagasEvaluatorChain**](https://docs.ragas.io/en/stable/howtos/integrations/langchain.html) abstraction as a decent starting point for making an custom generalizable evaluation routine. \n",
    "\n",
    "- **Trajectory Evaluation:** Using more advanced agent formulations, you can implement multiple-query strategies that assume the presence of conversational memory. With this, you can implement an evaluation agent which can:\n",
    "    - Ask a series of questions in order to evaluate how well the agent is able to adapt and cater to the scenario. This kind of system generally considers a series of correspondence and aims to tease out and evaluate a \"trajectory\" of how the agent navigated the conversation. The [**LangChain Trajectory Evaluators documentation**](https://python.langchain.com/v0.1/docs/guides/productionization/evaluation/trajectory/) is a good starting point.\n",
    "    - Alternatively, you could also implement an evaluation agent that tries to achieve objectives by interacting with the chatbot. Such an agent can output whether they were able to navigate to their solution in a natural manner, and can even be used to generate a report about the percieved performance. The [**LangChain Agents documentation**](https://python.langchain.com/v0.1/docs/modules/agents/) is a good starting point!\n",
    "\n",
    "<br>\n",
    "\n",
    "At the end of the day, just make sure to use the tools you have at your disposal appropriately. By this point in the course, you should already be well-acquainted with the LLM core value propositions: **They're powerful, scalable, predictable, controllable, and orchestratable... but will act unpredictably when you just expect them to work by default.** Assess your needs, formulate and validate your pipelines, give enough information, and add as much control as you can to make your system work consistently, efficiently, and effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61faee2c-e534-4c89-91ae-45c37835dba5",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "<br>\n",
    "\n",
    "## **Part 5: [Assessment]** Evaluating For Credit\n",
    "\n",
    "Welcome to the last exercise of the course! Hopefully you've enjoyed the material and are ready to actually get credit for these notebooks! For this part:\n",
    "\n",
    "- **Make sure you're in the course environment**\n",
    "- **Make sure `docstore_index/` has been uploaded to the course environment...**\n",
    "    - **...and contains [at least one Arxiv paper](https://arxiv.org/search/advanced) which has been updated recently.**\n",
    "- **Make sure you don't have some old session of [`09_langserve.ipynb`](09_langserve.ipynb) already occupying the port. Your assessment requires you to implement the new `/retriever` and `/generator` endpoints!!**\n",
    "\n",
    "**Objective:** On launch, [**`frontend/frontend_block.py`**](frontend/frontend_block.py) had several lines of code which trigger the course pass condition. Your objective is to invoke that series of commands by using your pipeline to pass the **Evaluation** check! Recall [`09_langserve.ipynb`](09_langserve.ipynb) and use it as a starting example! As a recommendation, consider duplicating it so that you can keep the original as an authoritative reference. \n",
    "\n",
    "**Once Finished:** While your course environment is still open, please navigate back to your course environment launcher area and click the **\"Assess Task\"** button! After that, you're all done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48e300ed-951c-4006-ac54-cbbd41251707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "var url = 'http://'+window.location.host+':8090';\n",
       "element.innerHTML = '<a style=\"color:green;\" target=\"_blank\" href='+url+'><h1>< Link To Gradio Frontend ></h1></a>';\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%js\n",
    "var url = 'http://'+window.location.host+':8090';\n",
    "element.innerHTML = '<a style=\"color:green;\" target=\"_blank\" href='+url+'><h1>< Link To Gradio Frontend ></h1></a>';"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aff364c-519e-435e-bf1d-ce68a12d13e0",
   "metadata": {
    "id": "5aff364c-519e-435e-bf1d-ce68a12d13e0"
   },
   "source": [
    "----\n",
    "\n",
    "<br>\n",
    "\n",
    "## <font color=\"#76b900\">**Congratulations On Completing The Course**</font>\n",
    "\n",
    "Hopefully this course was not only exciting and challenging, but also adequately prepared you for work on the cutting edge of LLM and RAG system development! Going forward, you should have the skills necessary to tackle industry-level challenges and explore RAG deployment with open-source models and frameworks.\n",
    "\n",
    "**Some NVIDIA-specific releases related to this that you may find interesting include:**\n",
    "- [**NVIDIA NIM**](https://www.nvidia.com/en-us/ai/), which offers microservice spinup routines that can be deployed on local compute.\n",
    "- [**TensorRT-LLM**](https://github.com/NVIDIA/TensorRT-LLM) is the current recommended framework for deploying GPU-accelerated LLM model engines in production settings.\n",
    "- [**NVIDIA's Generative AI Examples Repo**](https://github.com/NVIDIA/GenerativeAIExamples), which includes the current canonical microservice example application and will be updated with new resources as new production workflows get released.\n",
    "- [**The Knowledge-Based Chatbot Technical Brief**](https://resources.nvidia.com/en-us-generative-ai-chatbot-workflow/knowledge-base-chatbot-technical-brief) which discusses additional publicly-accessible details on productionalizing RAG systems.\n",
    "\n",
    "**Additionally, some key topics you may be interested in delving more into include:**\n",
    "- [**LlamaIndex**](https://www.llamaindex.ai/), which has strong components that can augment and occasionally improve upon the LangChain RAG features.\n",
    "- [**LangSmith**](https://docs.smith.langchain.com/), an upcoming agent productionalization service offered by LangChain.\n",
    "- [**Gradio**](https://www.gradio.app/), though touched on in the course, has many more interface options which will be worth investigating. For inspiration, consider checking out [**HuggingFace Spaces**](https://huggingface.co/spaces) for examples.\n",
    "- [**LangGraph**](https://python.langchain.com/docs/langgraph/) is a framework for graph-based LLM orchestration, and is a natural next step forward for those interested in [multi-agent workflows](https://blog.langchain.dev/langgraph-multi-agent-workflows/).\n",
    "- [**DSPy**](https://github.com/stanfordnlp/dspy), a flow engineering framework that allows you to optimize LLM orchestration pipelines based on empirical performance results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035451c9-ed12-4bc3-b468-04db5c399e03",
   "metadata": {
    "id": "035451c9-ed12-4bc3-b468-04db5c399e03"
   },
   "source": [
    "<center><a href=\"https://www.nvidia.com/en-us/training/\"><img src=\"https://dli-lms.s3.amazonaws.com/assets/general/DLI_Header_White.png\" width=\"400\" height=\"186\" /></a></center>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
