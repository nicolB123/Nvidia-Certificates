{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b007233-ee0a-4c5d-8165-4fdba076a8b4",
   "metadata": {},
   "source": [
    "<br>\n",
    "<a href=\"https://www.nvidia.com/en-us/training/\">\n",
    "    <div style=\"width: 55%; background-color: white; margin-top: 50px;\">\n",
    "    <img src=\"https://dli-lms.s3.amazonaws.com/assets/general/nvidia-logo.png\"\n",
    "         width=\"400\"\n",
    "         height=\"186\"\n",
    "         style=\"margin: 0px -25px -5px; width: 300px\"/>\n",
    "</a>\n",
    "<h1 style=\"line-height: 1.4;\"><font color=\"#76b900\"><b>Building Agentic AI Applications with LLMs</h1>\n",
    "<h2><b>Exercise 1:</b> Dataset Chat</h2>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d696341b-1f79-4c34-a9e6-ccc5dc411a45",
   "metadata": {},
   "source": [
    "**Welcome back! This is the first exercise in the course, so see what you can do!**\n",
    "\n",
    "This notebook serves as a hands-on exercise following the \"main-lecture\" notebook. The exercises in this series utilizes the same dataset to gradually help us enable more complex LLM interactions.\n",
    "\n",
    "In the previous notebook, we implemented a basic multi-agent system to generate synthetic multi-turn conversations. While useful for generating artificial dialogues, this implementation lacks practicality for end-user applications.\n",
    "\n",
    "### **Learning Objectives:**\n",
    "\n",
    "**In this notebook, we will:**\n",
    "\n",
    "- Build a simple user-facing chatbot that interacts with a dataset.\n",
    "- Address the challenge of handling datasets too large for our model’s context window.\n",
    "- Develop a summarization pipeline to preprocess data efficiently.\n",
    "\n",
    "This dataset will remain in use throughout the course, so our first step is to enable a simple interactive chat with it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ee8272-833f-4d4b-abce-351bafff3093",
   "metadata": {},
   "source": [
    "<hr><br>\n",
    "\n",
    "### **Part 1:** Setting Up A Workshop Assistant Chatbot\n",
    "\n",
    "From the previous exercise, you can specify a simple chatbot that interacts with the user using a simple loop. Based on this, the following function establishes a simple chatbot loop where a user can interact with an AI agent. If no processing function (chain) is provided, it defaults to an unimplemented generator that outputs a placeholder message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97a208ed-38b0-4730-a540-0de4e1612f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "[Human]: \n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "\n",
    "def not_implemented_gen(state):\n",
    "    \"\"\"A placeholder generator that informs users the chain is not yet implemented.\"\"\"\n",
    "    message = \"Chain Not Implemented. Enter with no inputs or interrupt execution to exit.\"\n",
    "    for letter in message:\n",
    "        yield letter\n",
    "        sleep(0.005)\n",
    "\n",
    "def chat_with_chain(state={}, chain=not_implemented_gen):\n",
    "    \"\"\"\n",
    "    Interactive chat function that processes user input through a specified chain.\n",
    "    \n",
    "    Parameters:\n",
    "        state (dict): Maintains chat history and context.\n",
    "        chain (callable): Function to generate responses based on the chat history.\n",
    "    \"\"\"\n",
    "    assert isinstance(state, dict)\n",
    "    state[\"messages\"] = state.get(\"messages\", [])\n",
    "    while True:\n",
    "        try:\n",
    "            human_msg = input(\"\\n[Human]:\")\n",
    "            if not human_msg.strip(): break\n",
    "            agent_msg = \"\"\n",
    "            state[\"messages\"] += [(\"user\", human_msg)]\n",
    "            print(flush=True)\n",
    "            print(\"[Agent]: \", end=\"\", flush=True)\n",
    "            for token in getattr(chain, \"stream\", chain)(state):\n",
    "                agent_msg += token\n",
    "                print(getattr(token, \"content\", token), end=\"\", flush=True)\n",
    "            state[\"messages\"] += [(\"ai\", agent_msg)]\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"KeyboardInterrupt\")\n",
    "            break\n",
    "\n",
    "## Initialize chat with the placeholder generator\n",
    "chat_with_chain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cd5d6c-8039-408e-a6cf-ac3081b7fdc7",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "From this, we can define a conversational pipeline with an LLM, a prompt template, and a starting state. A prompt, llm, and an output parser are provided, so please combine them together into a chain for your `chat_with_chain` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d974c15-ef48-4b64-9006-331a2530f3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "[Human]: What is RTX?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Agent]: RTX is a real-time graphics technology developed by NVIDIA. RTX enhances the performance of GPUs beyond traditional interactive rendering engines, enabling smoother frame rates, faster rendering, and feature enhancements. It uses AI-fueled GPUs ( Tensor RTX or RTX 3000 onwards) to predict about 1.5 seconds ahead in time, allowing for better spatial analysis, improved rendering, and more efficient data management. This technology is primarily used in games, video games, and desktop graphics performance.\n",
      "\n",
      "If you're looking for specific information about a Deep Learning (DL) use case related to RTX, please provide more details for a tailored response."
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "[Human]: \n"
     ]
    }
   ],
   "source": [
    "from langchain_nvidia import ChatNVIDIA\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from functools import partial\n",
    "\n",
    "## Define an NVIDIA-backed LLM\n",
    "# llm = ChatNVIDIA(model=\"meta/llama-3.1-8b-instruct\", base_url=\"http://llm_client:9000/v1\")\n",
    "llm = ChatNVIDIA(model=\"nvidia/llama-3.1-nemotron-nano-8b-v1\", base_url=\"http://llm_client:9000/v1\")\n",
    "\n",
    "## Define a structured prompt\n",
    "sys_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are a helpful assistant for NVIDIA Deep Learning Institute (DLI). \"\n",
    "     \"Assist users with their workshop-related queries using the provided context. \"\n",
    "     \"Do not reference the 'context' as 'context' explicitly.\"),\n",
    "    (\"user\", \"<context>\\n{context}</context>\"),\n",
    "    (\"ai\", \"Thank you. I will not restart the conversation and will abide by the context.\"),\n",
    "    (\"placeholder\", \"{messages}\")\n",
    "])\n",
    "\n",
    "## Construct the processing pipeline\n",
    "chat_chain = sys_prompt | llm | StrOutputParser()\n",
    "\n",
    "## Initialize chatbot state\n",
    "state = {\n",
    "    \"messages\": [(\"ai\", \"Hello! I'm the NVIDIA DLI Chatbot! How can I help you?\")],\n",
    "    \"context\": \"\",  # Empty for now; will be updated later\n",
    "}\n",
    "\n",
    "## Wrap function to integrate AI response generation\n",
    "chat = partial(chat_with_chain, chain=chat_chain)\n",
    "\n",
    "## Start the chatbot with the AI pipeline\n",
    "chat(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84db33c4-be56-49a8-984c-cb4a4192ec3d",
   "metadata": {},
   "source": [
    "<hr><br>\n",
    "\n",
    "### **Part 2:** Pulling In Some Context\n",
    "\n",
    "For this course, we will start by using a small dataset of workshop catalog from the GTC 2025 conference. This includes a real selection of workshops which were each proposed independently and vary in detail. This should be reminiscent of an organically-accumulated datapool... partially because it is one. The data can be found in [`gtc-data-2025.csv`](./gtc-data-2025.csv), so let's go ahead and load it in as a list!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66f05dd8-73a9-4044-9e36-81f4242c3ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Harness NVIDIA’s Advanced Tools for Gen AI in Digital Health',\n",
       "  'description': \"This training lab explores the cutting-edge capabilities of NVIDIA's suite of AI tools — NVIDIA Inference Microservices (NIMs) and NVIDIA AI Blueprints — in transforming digital health solutions. Gain hands-on experience developing sophisticated AI-driven applications that can converse with multimodal healthcare data, enhance clinician-patient interactions, and extract valuable insights from healthcare video content. Explore NVIDIA-optimized large language models (LLMs), advanced techniques like retrieval augmented generation (RAG) and agentic LLM systems, as well as applications in speech AI and digital human technology. We'll emphasize the practical aspects of deploying these GPU-accelerated technologies and customizing them to specific digital health scenarios.\",\n",
       "  'instructors': 'Jin Li // Katie Link'},\n",
       " {'name': 'Advanced Medical AI Development with MONAI: From Interactive Annotation to Foundation Models',\n",
       "  'description': 'This hands-on training lab demonstrates how to build end-to-end medical AI workflows using the latest tools: MONAI Label, VISTA-3D, MAISI, and VILA-M3. Learn to combine AI-assisted annotation, interactive segmentation, synthetic data generation, and advanced visual-language understanding to create powerful medical imaging applications. Gain practical experience with these tools while understanding how they complement each other in real-world scenarios.',\n",
       "  'instructors': 'Ahmed Harouni'},\n",
       " {'name': 'Building Digital Twin Environments With OpenUSD, NVIDIA Isaac Sim, and ROS: A Hands-On Approach to Robotics Simulation',\n",
       "  'description': \"This lab focuses on creating a digital twin environment and simulating robots within it. Learn to assemble a virtual environment using 3D CAD data with OpenUSD, NVIDIA Omniverse, and USD Search NIM. Then explore NVIDIA Isaac Sim to add virtual robots to the scene and simulate their basic movements with ROS commands. The lab will emphasize data aggregation, environment creation, and initial robot simulation.\\n \\n By the end of this lab, you'll be able to create a detailed digital twin environment and simulate basic robot movements within it using the Robot Operating System (ROS). This lab is designed for developers interested in digital twin technology and robotics simulation in industrial settings.\",\n",
       "  'instructors': 'Ayush Ghosh // Steven Feng'},\n",
       " {'name': 'Build Your First AI Robotic Arm With OpenVLA and Isaac Sim',\n",
       "  'description': \"Physical AI is transforming many industries. Get a hands-on introduction to creating a simulated robotic arm using OpenVLA, a state-of-the-art, open-source vision-language-action (VLA) model, and NVIDIA Isaac Sim, a high-fidelity simulation platform for robotics. Learn how to set up and integrate these tools to simulate and control a robotic arm. We'll cover the basics of pre-trained VLA models and offer practical guidance on fine-tuning these models for specific tasks using LORA. Then, you'll use IsaacSim to simulate and control a simulated robotic arm. In the end, you'll have the foundation to build and adapt robotic applications in a simulated environment, paving the way for future exploration and development in robotics without the need for costly physical hardware. The workshop is structured like this:\\n \\n 1. Introduction to OpenVLA (20 mins)\\n 2. Lab training fine-tuning (30 mins)\\n 3. IsaacSim (20 min)\\n 4. Lab deploy OpenVLA to IsaacSim (30 mins)\",\n",
       "  'instructors': 'Abubakr Karali // Maycon da Silva Carvalho // Teresa Conceicao'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "## Load dataset\n",
    "filepath = \"gtc-data-2025.csv\"\n",
    "df = pd.read_csv(filepath)\n",
    "\n",
    "## Convert to JSON for structured processing\n",
    "raw_entries = json.loads(df.to_json(orient=\"records\"))\n",
    "\n",
    "## Display the first few records\n",
    "raw_entries[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef7a275-fdda-4cb1-9ffb-4f4c0e153f06",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "We can quickly process them into a more natural format, and then try to concatenate them together to create a viable \"context string\" for our model. Automation to create context is quite common in real workflows to augment LLMs, so no reason not to do it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "418e8f53-63b8-42f3-a391-a18d407134f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Context Length (characters): 50559\n",
      "----------------------------------------\n",
      "The following workshops are slated to be presented at NVIDIA's GTC 2025 Conference:\n",
      "\n",
      "[Session 1]\n",
      "Harness NVIDIA’s Advanced Tools for Gen AI in Digital Health\n",
      "Presenters: Jin Li // Katie Link\n",
      "Description: This training lab explores the cutting-edge capabilities of NVIDIA's suite of AI tools — NVIDIA Inference Microservices (NIMs) and NVIDIA AI Blueprints — in transforming digital health solutions. Gain hands-on experience developing sophisticated AI-driven applications that can converse with multimodal healthcare data, enhance clinician-patient interactions, and extract valuable insights from healthcare video content. Explore NVIDIA-optimized large language models (LLMs), advanced techniques like retrieval augmented generation (RAG) and agentic LLM systems, as well as applications in speech AI and digital human technology. We'll emphasize the practical aspects of deploying these GPU-accelerated technologies and customizing them to specific digital health scenarios.\n",
      "\n",
      "[Session 2]\n",
      "Advanced Medical AI Development with MONAI: From Interactive Annotation to Foundation Models\n",
      "Presenters: Ahmed Harouni\n",
      "Description: This hands-on training lab demonstrates how to build end-to-end medical AI workflows using the latest tools: MONAI Label, VISTA-3D, MAISI, and VILA-M3. Learn to combine AI-assisted annotation, interactive segmentation, synthetic data generation, and advanced visual-language understanding to create powerful medical imaging applications. Gain practical experience with these tools while understanding how they complement each other in real-world scenarios.\n",
      "\n",
      "[Session 3]\n",
      "Building Digital Twin Environments With OpenUSD, NVIDIA Isaac Sim, and ROS: A Hands-On Approach to Robotics Simulation\n",
      "Presenters: Ayush Ghosh // Steven Feng\n",
      "Description: This lab focuses on creating a digital twin environment and simulating robots within it. Learn to assemble a virtual environment using 3D CAD data with OpenUSD, NVIDIA Omniverse, and USD Search NIM. Then explore NVIDIA Isaac Sim to add\n"
     ]
    }
   ],
   "source": [
    "def stringify(entry, description_key='description'):\n",
    "    \"\"\"Formats workshop details into a human-readable string.\"\"\"\n",
    "    return (\n",
    "        f\"{entry.get('name')}\\n\"\n",
    "        f\"Presenters: {entry.get('instructors')}\\n\"\n",
    "        f\"Description: {entry.get(description_key)}\"\n",
    "    )\n",
    "\n",
    "## Convert dataset entries to structured text\n",
    "raw_blurbs = [\n",
    "    f\"[Session {i+1}]\\n{stringify(entry)}\" \n",
    "    for i, entry in enumerate(raw_entries)\n",
    "]\n",
    "\n",
    "## Construct full context string\n",
    "raw_context = \"The following workshops are slated to be presented at NVIDIA's GTC 2025 Conference:\\n\\n\"\n",
    "raw_context += \"\\n\\n\".join(raw_blurbs)\n",
    "\n",
    "## Display context statistics\n",
    "print(f\"Full Context Length (characters): {len(raw_context)}\")\n",
    "print(\"-\"*40)\n",
    "print(raw_context[:2000])  # Preview the first portion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b1e5172-768e-4d06-8aee-7e2c9d647783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "[Human]: Tell me about NVIDIA GenAI\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Agent]: NVIDIA GenAI is a comprehensive platform that enables businesses to transition to a more efficient, agile, and constantly improving for AI-driven systems through NVIDIA's cutting-edge hardware and software. GenAI is built using NVIDIA's data architecture and data analytics platforms, and it is designed to work with NVIDIA Ajinom AI, Tesla GBS and T4 chips, GPUs, Tegra processors, and more. GenAI's solutions include the NVIDIA A100 GPU, which offers large memory bandwidth, typically, up to 32GB and a large tensor modeling size. GenAI offers several AI solutions and tools including NVIDIA's AI software solution which is a comprehensive toolkit for building and deploying AI models for a wide range of applications. GenAI is structured to enable developers and businesses to accelerate AI development, collaboration, and driftwood these solutions have been developed to optimize for long-term scaling and may be utilized by companies including Disney, McDonald's, Accentisys, Honeywell and SpaceX.\n",
      "\n",
      "GenAI is designed to support both the development and the deployment of AI models. One way it is achieved is through the use of NVIDIA Research Citizenship program and collaborations with universities and research labs, enabling the development of advanced AI through community-focused initiatives. For application areas where a diverse set of hardware is needed to run different AI acre rates together, GenAI allows for best use of resources and supported various formalities such as Protile AI, which is a software solution for develop AI applications on NVIDIA devices.\n",
      "\n",
      "GenAI also empowers customers' hardware and development teams with the tools needed to handle large-scale AI tasks. It includes support for various industry applications such as entertainment, retail and industrial. "
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "[Human]: \n"
     ]
    }
   ],
   "source": [
    "## Using your previous abstraction, pass the context into your prompt and see if it works:\n",
    "## TODO: Initialize your state based on your opinionated chat chain\n",
    "state = {\n",
    "    \"messages\": [],\n",
    "    \"context\": raw_context,\n",
    "}\n",
    "\n",
    "try:\n",
    "    ## TODO: Perform the conversation with your long context (it's ok if it fails)\n",
    "    chat(state)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933a3275-511f-402d-84be-cb12b5a8ae58",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<details><summary><b>Hint</b></summary>\n",
    "\n",
    "Recall that we just have a `chat` function which wraps a reusable chain. So we can just invoke it using `chat(state)` for some `state`. Then, we just need to figure out what should go in our prompt. To refresh your memory:\n",
    "\n",
    "```python\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are a helpful instructor assistant for NVIDIA Deep Learning Institute (DLI). \"\n",
    "     \"Assist users with their course-related queries using the provided context. \"\n",
    "     \"Do not reference the 'context' as 'context' explicitly.\"),\n",
    "    (\"user\", \"<context>\\n{context}</context>\"),\n",
    "    (\"ai\", \"Thank you. I will not restart the conversation and will abide by the context.\"),\n",
    "    (\"placeholder\", \"{messages}\")\n",
    "])\n",
    "\n",
    "```\n",
    "\n",
    "</details>\n",
    "<details><summary><b>Solution</b></summary>\n",
    "\n",
    "Given that our prompt expects to take in a dictionary which includes a `context` (interpretable as strings) and `messages` (interpretable as a list of messages like `[(\"user\", \"Hello World\")]`), we can initiate our prompt with no message history and the `raw_context` as our context.\n",
    "\n",
    "```python\n",
    "state = {\"messages\": [], \"context\": raw_context,}\n",
    "try:\n",
    "    chat(state)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "```\n",
    "\n",
    "</details>\n",
    "<br>\n",
    "\n",
    "Depending on the model settings, the context is likely either too long for the endpoint or the results are subpar. We can test how many tokens our input actually required with the help of a [tokenizer](https://huggingface.co/unsloth/Meta-Llama-3.1-8B-Instruct/blob/main/tokenizer.json) and can maybe make some assumptions about our model limitations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbea4244-8242-48a5-b1cf-fcf27dde1290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String Length of Context: 50559\n",
      "Token Length of Context: 10107\n",
      "The following workshops are slated to be presented at NVIDIA's GTC 2025 Conference:\n",
      "\n",
      "[Session 1]\n",
      "Harness NVIDIA’s Advanced Tools for Gen AI in Digital Health\n",
      "Presenters: Jin Li // Katie Link\n",
      "Description: This training lab explores the cutting-edge capabilities of NVIDIA's suite of AI tools — NVIDIA Inference Microservices (NIMs) and NVIDIA AI Blueprints — in transforming digital health solutions. Gain hands-on experience developing sophisticated AI-driven applications that can converse with multimodal healthcare data, enhance clinician-patient interactions, and extract valuable insights from healthcare video content. Explore NVIDIA-optimized large language models (LLMs), advanced techniques like retrieval augmented generation (RAG) and agentic LLM systems, as well as applications in speech AI and digital human technology. We'll emphasize the practical aspects of deploying these GPU-accelerated technologies and customizing them to specific digital health scenarios.\n",
      "\n",
      "[Session 2]\n",
      "Advanced Medical AI Development with MONAI: From Interactive Annotation to Foundation Models\n",
      "Presenters: Ahmed Harouni\n",
      "Description: This hands-on training lab demonstrates how to build end-to-end medical AI workflows using the latest tools: MONAI Label, VISTA-3D, MAISI, and VILA-M3. Learn to combine AI-assisted annotation, interactive segmentation, synthetic data generation, and advanced visual-language understanding to create powerful medical imaging applications. Gain practical experience with these tools while understanding how they complement each other in real-world scenarios.\n",
      "\n",
      "[Session 3]\n",
      "Building Digital Twin Environments With OpenUSD, NVIDIA Isaac Sim, and ROS: A Hands-On Approach to Robotics Simulation\n",
      "Presenters: Ayush Ghosh // Steven Feng\n",
      "Description: This lab focuses on creating a digital twin environment and simulating robots within it. Learn to assemble a virtual environment using 3D CAD data with OpenUSD, NVIDIA Omniverse, and USD Search NIM. Then explore NVIDIA Isaac Sim to add\n"
     ]
    }
   ],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "llama_tokenizer = PreTrainedTokenizerFast(tokenizer_file=\"tokenizer.json\", clean_up_tokenization_spaces=True)\n",
    "\n",
    "def token_len(text):\n",
    "    \"\"\"Counts token length of given text.\"\"\"\n",
    "    return len(llama_tokenizer.encode(text=text))\n",
    "\n",
    "print(f\"String Length of Context: {len(raw_context)}\")\n",
    "print(f\"Token Length of Context: {token_len(raw_context)}\")\n",
    "\n",
    "## Preview context\n",
    "print(raw_context[:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14702102-4fb0-46ef-9fcc-2e720a1a1c5d",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**You may be thinking \"don't most models have much longer contexts,\" and you would be right with a few key caveats:**\n",
    "\n",
    "- Using an API service, you would still be paying for the tokens anyway, so maybe having a long static context isn't the best idea?\n",
    "- Even if your context length is supported, most models still experience some amount of quality degredation as your inputs get longer. Furthermore, more inputs = more opportunities for conflicting data and text structures.\n",
    "- For an arbitrary document or even a document pool, you are likely to find yourself stretching into max context more often than not. Even if a model is good for this dataset, will it still work well for a database?\n",
    "\n",
    "In our case, we are operating on a sample of course descriptions of various detail and quality, which adds up to a large pool of inconsistent entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4d0eee7-d819-45fa-9776-8127f6611279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHORTEST ENTRIES:\n",
      "[Session 12]\n",
      "An Introduction to NVIDIA Cosmos for Physical AI\n",
      "Presenters: None\n",
      "Description: None \n",
      "\n",
      "[Session 27]\n",
      "CUTLASS Walkthrough\n",
      "Presenters: Vijay Thakkar\n",
      "Description: Join our walkthrough for everything new in CUTLASS such as Blackwell, Flash Attention 3, and Python Interface. We'll mix lecture portions with hands-on examples. \n",
      "\n",
      "[Session 50]\n",
      "Accelerating Clustering Algorithms to Achieve the Highest Performance\n",
      "Presenters: Allison Ding\n",
      "Description: Clustering is commonly applied across industries for applications such as recommendation systems and fraud detection. In this lab, through examples, we will discuss techniques to accelerate common clustering algorithms and tips/tricks to derive the highest performance. \n",
      "\n",
      "[Session 4]\n",
      "Build Your First AI Robotic Arm With OpenVLA and Isaac Sim\n",
      "Presenters: Abubakr Karali // Maycon da Silva Carvalho // Teresa Conceicao\n",
      "Description: Physical AI is transforming many industries. Get a hands-on introduction to creating a simulated robotic arm using OpenVLA, a state-of-the-art, open-source vision-language-action (VLA) model, and NVIDIA Isaac Sim, a high-fidelity simulation platform for robotics. Learn how to set up and integrate these tools to simulate and control a robotic arm. We'll cover the basics of pre-trained VLA models and offer practical guidance on fine-tuning these models for specific tasks using LORA. Then, you'll use IsaacSim to simulate and control a simulated robotic arm. In the end, you'll have the foundation to build and adapt robotic applications in a simulated environment, paving the way for future exploration and development in robotics without the need for costly physical hardware. The workshop is structured like this:\n",
      " \n",
      " 1. Introduction to OpenVLA (20 mins)\n",
      " 2. Lab training fine-tuning (30 mins)\n",
      " 3. IsaacSim (20 min)\n",
      " 4. Lab deploy OpenVLA to IsaacSim (30 mins) \n",
      "\n",
      "[Session 35]\n",
      "“I See Dead Pipelines...Without CI/CD:\" The Gen AI Easy Button for Fine-Tuning, Evaluation, and Inference With NVIDIA NIMs and Nemo Microservices\n",
      "Presenters: Anshul Jindal // Dmitry Mironov // Martin Piercy\n",
      "Description: \"Dead pipelines\" — abandoned scripts that once ran parts of a workflow — plague LLM development, causing errors, delays, and wasted resources. Learn how to automate the entire LLM life cycle using CI/CD pipelines, Kubernetes, NVIDIA NIMs, and Nemo Microservices in a cloud-agnostic approach. Discover how to streamline development, fine-tuning, evaluation, and deployment of LLMs, ensuring seamless integration, validation, and deployment of updates.\n",
      " \n",
      " In this hands-on course, you'll:\n",
      " \n",
      " • Design and build a cloud-agnostic LLMOps CI/CD pipeline on Kubernetes for scalable and flexible Gen AI app deployment\n",
      " • Utilize Argo CD for declarative continuous delivery and Argo Workflows for managing complex LLM workflows\n",
      " • Leverage NVIDIA NIMs and NeMo Microservices in the end-to-end LLMOps pipeline\n",
      " • Learn how to improve development cycles, accuracy, and reliability with automated fine-tuning and continuous evaluation \n",
      "\n",
      "[Session 21]\n",
      "Build Next-Gen Agents With Large Vision Language Models\n",
      "Presenters: Abubakr Karali // Debraj Sinha // Sammy Ochoa\n",
      "Description: Vision-language models (VLM) are taking computer vision by storm, offering scalability and robust zero-shot solution for countless industries. However, there are many challenges along the way to deploying VLMs. In this workshop, we'll demystify these challenges. You'll learn what VLMs are, and we'll show you how to choose the best model, how to train and fine-tune on a small dataset, and how to deploy and use VLMs scene understanding with NVIDIA Nemo. Then we'll show different workflows for VLM deployment, with NIMs and VIA including grounding the models for more accurate results. \n",
      " \n",
      " The workshop will be structured as follows:\n",
      " 1) Introduction to VLMs (40 mins)\n",
      " a. Families of VLMs \n",
      " b. Choice of the right VLMs\n",
      " c. Training/evaluation\n",
      " d. Fine-tuning\n",
      " e. Where to start\n",
      " 2) Introduction NIMs (10 mins)\n",
      " 3) Hands-on experience with VLM models through NIMs (20 mins)\n",
      " 4) Introduction to VIA (10 mins)\n",
      " 5) Deploy VLM with VIA reference application (20 mins) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "sorted_raw_blurbs = sorted(raw_blurbs, key=token_len)\n",
    "\n",
    "def plot_token_len(entries, color=\"green\", alpha=1, len_fn=token_len):\n",
    "    \"\"\"Plots token lengths of all entries.\"\"\"\n",
    "    plt.bar(x=range(len(entries)), height=[len_fn(v) for v in entries], width=1.0, color=color, alpha=alpha)\n",
    "\n",
    "plot_token_len(sorted_raw_blurbs, color=\"green\")\n",
    "plt.xlabel(\"Entry Sample Number\")\n",
    "plt.ylabel(\"Token Length\")\n",
    "plt.show() \n",
    "\n",
    "print(\"SHORTEST ENTRIES:\")\n",
    "sample_blurbs = sorted_raw_blurbs[:3] + sorted_raw_blurbs[-3:]\n",
    "\n",
    "for entry in sample_blurbs:\n",
    "    print(entry, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a997a46-37b3-4461-ae0f-e35b2ebdad6e",
   "metadata": {},
   "source": [
    "<hr><br>\n",
    "\n",
    "### **Part 3:** Summarizing Our Long Context\n",
    "\n",
    "Maybe we can convert each of these entries into something shorter and more uniform? Maybe as a preprocessing step, we can just process all of these entries into a more consistent form. Not only will this help our model reason about the full context, but we'll also be able to leverage the entries' uniform nature to improve the consistency of our prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0475ac8a-536c-4ed6-b4a6-8f2a2a91cbda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Summary) This hands-on training lab focuses on advanced medical AI development using MONAI tools: Lab, 3D, MAISI, and VILA-M3. Participants will learn to build end-to-end workflows including AI-assisted annotation, interactive segmentation, synthetic data generation, and AI for visual-language understanding, ensuring interoperability and real-world applicability. Key details include the presenter, Ahmed Harouni, and the goal of gaining practical experience with these tools. The audience benefits from understanding how these technologies complement each other in real scenarios. No additional facts are included.\n",
      "CPU times: user 7.43 ms, sys: 466 μs, total: 7.89 ms\n",
      "Wall time: 1.86 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## TODO: Create a symmary system message to instruct the LLM.\n",
    "## Reuse the chat_chain as-it-was, remembering that it expects \"messages\" and \"context\"\n",
    "summary_msg = (\n",
    "    \"Summarize the presentation description down to only a few important sentences. \"\n",
    "    \"Preserve key details (topic, audience, prerequisites, tools/tech, and outcomes). \"\n",
    "    \"Do not add facts that are not present. \"\n",
    "    \"Start with '(Summary) ' and keep it concise.\"\n",
    ")\n",
    "\n",
    "def summarize(context_str, summary_msg=summary_msg):\n",
    "    return chat_chain.invoke({\n",
    "        \"messages\": [(\"user\", summary_msg)],\n",
    "        \"context\": context_str,\n",
    "    })\n",
    "\n",
    "print(summarize(stringify(raw_entries[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497fece0-31e4-4dde-8059-1b196c376093",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<details><summary><b>Solution</b></summary>\n",
    "\n",
    "```python\n",
    "return chat_chain.invoke({\n",
    "    \"messages\": [(\"user\", summary_msg)],\n",
    "    \"context\": context_str\n",
    "})\n",
    "```\n",
    "\n",
    "</details>\n",
    "<br>\n",
    "\n",
    "It's natural language and not required to be well-formatted, but we can sufficiently prompt-engineer it for a simple text-to-text transformation function. We can also use the LangChain batching primitives to greatly simplify our concurrency management:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15264663-4e21-479f-9d16-3a7172975165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6e4f5f76c2a4cb397a62b79ffa1b0bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 310 ms, sys: 67.8 ms, total: 378 ms\n",
      "Wall time: 7.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from tqdm.auto import tqdm\n",
    "import threading\n",
    "\n",
    "batch_inputs = [stringify(entry_dict) for entry_dict in raw_entries]\n",
    "\n",
    "## Simple version of a batched process. No progress bar\n",
    "# summaries = RunnableLambda(summarize).batch(batch_inputs, config={\"max_concurrency\": 20})\n",
    "\n",
    "## Modified version which also has progress bars! Marginally-slower, same backbone\n",
    "def batch_process(fn, inputs, max_concurrency=20):\n",
    "    lock = threading.Lock()\n",
    "    pbar = tqdm(total=len(inputs))\n",
    "    def process_doc(value):\n",
    "        try:\n",
    "            output = fn(value)\n",
    "        except Exception as e: \n",
    "            print(f\"Exception in thread: {e}\")\n",
    "        with lock:\n",
    "            pbar.update(1)\n",
    "        return output\n",
    "    try:\n",
    "        lc_runnable = fn if hasattr(fn, \"batch\") else RunnableLambda(process_doc)\n",
    "        return lc_runnable.batch(inputs, config={\"max_concurrency\": max_concurrency})\n",
    "    finally:\n",
    "        pbar.close()\n",
    "\n",
    "summaries = batch_process(summarize, batch_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de06df66-ec7d-4892-94c7-eb97df4558f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"(Summary) This training lab focuses on NVIDIA's advanced AI tools like NIMs and AI Blueprints, applied in digital health. Presenters: Jin Li and Katie Link. The workshop aims to help participants develop AI-driven solutions for conversing with multimodal healthcare data, enhancing clinician-patient interactions, and analyzing healthcare video content. Key tools include GPU-accelerated large language models (LLMs), advanced techniques like Retrieval Augmented Generation (RAG) and agentic LLM systems, and applications in speech AI and digital human technology. The session emphasizes practical deployment and customization of these technologies for specific digital health scenarios. Prerequisites include basic knowledge of AI and GPU acceleration. Outcomes include hands-on experience with state-of-the-art AI tools tailored for digital health applications.\",\n",
       " '(Summary) This hands-on training lab focuses on advanced medical AI development using MONAI tools. Users will learn to use MONAI Label, VISTA-3D, MAISI, and VILA-M3 to build end-to-end workflows, including AI-assisted annotation, interactive segmentation, synthetic data generation, and advanced visual-language understanding. The presentation provides practical experience with these tools and explains how they work together in real-world medical imaging applications. No prerequisites are mentioned, but this session assumes some familiarity with AI and deep learning concepts.',\n",
       " '(Summary) The presentation covers building a digital twin environment and simulating robots using OpenUSD, NVIDIA Isaac Sim, and ROS. Designed for developers, it focuses on assembling virtual environments, data aggregation, and initial robot movement simulation in industrial settings. Key tools and technologies include 3D CAD data with OpenUSD, NVIDIA Omniverse, and USD Search NIM, and NVIDIA Isaac Sim with ROS commands. Outcomes include the ability to create a detailed digital twin environment and simulate basic robot movements.',\n",
       " '(Summary) The presentation introduces building a simulated robotic arm using OpenVLA and NVIDIA Isaac Sim. Learn how to set up, integrate, fine-tune VLA models, and deploy them on IsaacSim for a hassle-free robotics simulation. The workshop covers topics like topic (AI robotics simulations), audience (presenters discuss and teach), prerequisites (OpenVLA, IsaacSim, LORA), tools/tech (OpenVLA, IsaacSim, LORA), and outcomes (online training, simulation, and adaptation). No additional facts were added.',\n",
       " '(Summary) This presentation focuses on advanced robot learning, utilizing digital twins and NVIDIA Isaac Sim and Lab. Topic: Profit from AI-powered robotics and machine learning in industrial settings by implementing techniques like simulation, task generation, and imitation learning. Prerequisites: Foundation in robotics simulation. Tools/Techn: NVIDIA Isaac Sim and Lab. Outcome: Train AI-powered robots in virtual environments, preparing them for real-world deployment. Audience: Developers with a background in robotics simulation.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b68b853-1c83-4ad6-98cf-22e970211229",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Now that we have this new summary, we can see what happens when we use this synthetic description instead of our original ones, and consider how our context length is reduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2f79fb0-1b82-4ae8-b6c4-454d98d0be2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harness NVIDIA’s Advanced Tools for Gen AI in Digital Health\n",
      "Presenters: Jin Li // Katie Link\n",
      "Description: This training lab focuses on NVIDIA's advanced AI tools like NIMs and AI Blueprints, applied in digital health. Presenters: Jin Li and Katie Link. The workshop aims to help participants develop AI-driven solutions for conversing with multimodal healthcare data, enhancing clinician-patient interactions, and analyzing healthcare video content. Key tools include GPU-accelerated large language models (LLMs), advanced techniques like Retrieval Augmented Generation (RAG) and agentic LLM systems, and applications in speech AI and digital human technology. The session emphasizes practical deployment and customization of these technologies for specific digital health scenarios. Prerequisites include basic knowledge of AI and GPU acceleration. Outcomes include hands-on experience with state-of-the-art AI tools tailored for digital health applications.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'Harness NVIDIA’s Advanced Tools for Gen AI in Digital Health',\n",
       " 'description': \"This training lab explores the cutting-edge capabilities of NVIDIA's suite of AI tools — NVIDIA Inference Microservices (NIMs) and NVIDIA AI Blueprints — in transforming digital health solutions. Gain hands-on experience developing sophisticated AI-driven applications that can converse with multimodal healthcare data, enhance clinician-patient interactions, and extract valuable insights from healthcare video content. Explore NVIDIA-optimized large language models (LLMs), advanced techniques like retrieval augmented generation (RAG) and agentic LLM systems, as well as applications in speech AI and digital human technology. We'll emphasize the practical aspects of deploying these GPU-accelerated technologies and customizing them to specific digital health scenarios.\",\n",
       " 'instructors': 'Jin Li // Katie Link',\n",
       " 'summary': \"This training lab focuses on NVIDIA's advanced AI tools like NIMs and AI Blueprints, applied in digital health. Presenters: Jin Li and Katie Link. The workshop aims to help participants develop AI-driven solutions for conversing with multimodal healthcare data, enhancing clinician-patient interactions, and analyzing healthcare video content. Key tools include GPU-accelerated large language models (LLMs), advanced techniques like Retrieval Augmented Generation (RAG) and agentic LLM systems, and applications in speech AI and digital human technology. The session emphasizes practical deployment and customization of these technologies for specific digital health scenarios. Prerequisites include basic knowledge of AI and GPU acceleration. Outcomes include hands-on experience with state-of-the-art AI tools tailored for digital health applications.\"}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#############################################################################\n",
    "## Defined Earlier\n",
    "\n",
    "# def stringify(entry, description_key='description'):\n",
    "#     return (\n",
    "#         f\"{entry.get('name')}\"\n",
    "#         f\"\\nPresentors: {entry.get('instructors')}\"\n",
    "#         f\"\\nDescription: {entry.get(description_key)}\"\n",
    "#     )\n",
    "\n",
    "## Defined Earlier\n",
    "#############################################################################\n",
    "\n",
    "for summary, pres_entry in zip(summaries, raw_entries):\n",
    "    words = summary.split()\n",
    "    ## Remove \"summary\" or \"(summary)\" from text\n",
    "    if \"summary\" in words[0].lower():\n",
    "        words = words[1:]\n",
    "    pres_entry[\"summary\"] = \" \".join(words)\n",
    "\n",
    "print(stringify(raw_entries[0], \"summary\"))\n",
    "raw_entries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d0ac496-bc50-4569-8cf0-7c815da7e597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAGwCAYAAABPSaTdAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAMZdJREFUeJzt3XtUVPX+//HXIAKiXELllkh4S81rWkpaWpJ4yfTo6WqFaZoGmtLpqC01tRRPpzppy7x0Uft+82h1jhWWlKHiSSHT5KdmmRonLLlUxkVNVNi/P/w6NSHE4Awz7Hk+1pq1mP3Zs+e9P7rw5Wd/PntbDMMwBAAAYFJeri4AAADAmQg7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1LxdXYA7qKio0PHjxxUQECCLxeLqcgAAQA0YhqHS0lJFRkbKy6vq8RvCjqTjx48rKirK1WUAAIBaOHbsmFq0aFFlO2FHUkBAgKQLnRUYGOjiagAAQE2UlJQoKirK+u94VQg7kvXSVWBgIGEHAIB65o+moDBBGQAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmJq3qwsAAAD138OpD1fZtmLYijqspDJGdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKl5u7oAAABQfzyc+rCrS7AbIzsAAMDUCDsAAMDUXBp2UlJSdN111ykgIEChoaEaMWKEDh06ZLNP//79ZbFYbF4TJ0602Sc3N1dDhw6Vv7+/QkND9fjjj+v8+fN1eSoAAMBNuXTOTkZGhhITE3Xdddfp/PnzeuKJJzRw4EAdPHhQjRs3tu43fvx4zZ8/3/re39/f+nN5ebmGDh2q8PBw7dy5U3l5eXrggQfUsGFDLVy4sE7PBwAAuB+Xhp20tDSb96tXr1ZoaKj27Nmjm266ybrd399f4eHhlzzGRx99pIMHD+rjjz9WWFiYunXrpqeeekrTp0/X3Llz5ePjU+kzZWVlKisrs74vKSlx0BkBAAB341ZzdoqLiyVJISEhNtvfeOMNNWvWTJ06ddLMmTN1+vRpa1tmZqY6d+6ssLAw67b4+HiVlJToiy++uOT3pKSkKCgoyPqKiopywtkAAAB34DZLzysqKjR16lT16dNHnTp1sm6/9957FR0drcjISO3bt0/Tp0/XoUOH9O9//1uSlJ+fbxN0JFnf5+fnX/K7Zs6cqeTkZOv7kpISAg8AAP+nPi4vr47bhJ3ExEQdOHBAn3zyic32CRMmWH/u3LmzIiIiNGDAAB09elStW7eu1Xf5+vrK19f3suoFAAD1g1tcxkpKStLGjRu1detWtWjRotp9e/XqJUk6cuSIJCk8PFwFBQU2+1x8X9U8HwAA4DlcGnYMw1BSUpI2bNigLVu2KCYm5g8/k52dLUmKiIiQJMXGxmr//v0qLCy07rN582YFBgaqY8eOTqkbAADUHy69jJWYmKi1a9fq3XffVUBAgHWOTVBQkBo1aqSjR49q7dq1GjJkiJo2bap9+/Zp2rRpuummm9SlSxdJ0sCBA9WxY0fdf//9euaZZ5Sfn69Zs2YpMTGRS1UAAMC1IzvLli1TcXGx+vfvr4iICOtr/fr1kiQfHx99/PHHGjhwoNq3b6/HHntMo0aNUmpqqvUYDRo00MaNG9WgQQPFxsbqvvvu0wMPPGBzXx4AAOC5XDqyYxhGte1RUVHKyMj4w+NER0frgw8+cFRZAADARNxigjIAAICzEHYAAICpEXYAAICpEXYAAICpEXYAAICpEXYAAICpEXYAAICpEXYAAICpEXYAAICpEXYAAICpEXYAAICpEXYAAICpEXYAAICpufSp5wAAwDUeTn3Y1SXUGUZ2AACAqRF2AACAqRF2AACAqRF2AACAqRF2AACAqbEaCwAAk/KkFVfVYWQHAACYGmEHAACYGmEHAACYGmEHAACYGmEHAACYGmEHAACYGkvPAQCo51hiXj1GdgAAgKkxsgMAQD3A6E3tMbIDAABMjbADAABMjbADAABMjbADAABMjbADAABMjbADAABMjbADAABMjbADAABMjbADAABMjbADAABMjbADAABMjbADAABMjbADAABMjbADAABMjbADAABMjbADAABMzdvVBQAA4GkeTn3Y1SV4FEZ2AACAqTGyAwCAEzB64z4IOwAA1BKBpn7gMhYAADA1wg4AADA1wg4AADA1wg4AADA1l4adlJQUXXfddQoICFBoaKhGjBihQ4cO2exz5swZJSYmqmnTpmrSpIlGjRqlgoICm31yc3M1dOhQ+fv7KzQ0VI8//rjOnz9fl6cCAADclEvDTkZGhhITE5WVlaXNmzfr3LlzGjhwoE6dOmXdZ9q0aUpNTdVbb72ljIwMHT9+XCNHjrS2l5eXa+jQoTp79qx27typNWvWaPXq1ZozZ44rTgkAALgZi2EYhquLuOiHH35QaGioMjIydNNNN6m4uFjNmzfX2rVr9ec//1mS9NVXX6lDhw7KzMxU7969tWnTJt122206fvy4wsLCJEnLly/X9OnT9cMPP8jHx+cPv7ekpERBQUEqLi5WYGCgU88RAGAeLD2vmRXDVjjluDX999ut5uwUFxdLkkJCQiRJe/bs0blz5xQXF2fdp3379mrZsqUyMzMlSZmZmercubM16EhSfHy8SkpK9MUXX1zye8rKylRSUmLzAgAA5uQ2YaeiokJTp05Vnz591KlTJ0lSfn6+fHx8FBwcbLNvWFiY8vPzrfv8NuhcbL/YdikpKSkKCgqyvqKiohx8NgAAwF24TdhJTEzUgQMHtG7dOqd/18yZM1VcXGx9HTt2zOnfCQAAXMMtHheRlJSkjRs3avv27WrRooV1e3h4uM6ePauioiKb0Z2CggKFh4db99m1a5fN8S6u1rq4z+/5+vrK19fXwWcBAMCvIlpHVNmWdzSvDiupG0G5Qa4uoUouHdkxDENJSUnasGGDtmzZopiYGJv2Hj16qGHDhkpPT7duO3TokHJzcxUbGytJio2N1f79+1VYWGjdZ/PmzQoMDFTHjh3r5kQAAIDbcunITmJiotauXat3331XAQEB1jk2QUFBatSokYKCgjRu3DglJycrJCREgYGBmjx5smJjY9W7d29J0sCBA9WxY0fdf//9euaZZ5Sfn69Zs2YpMTGR0RsAAODasLNs2TJJUv/+/W22r1q1SmPGjJEk/eMf/5CXl5dGjRqlsrIyxcfH66WXXrLu26BBA23cuFGTJk1SbGysGjdurISEBM2fP7+uTgMAALgxl4admtzix8/PT0uXLtXSpUur3Cc6OloffPCBI0sDAAAm4TarsQAAAJyBsAMAAEyNsAMAAEyNsAMAAEyNsAMAAEyNsAMAAEzNLR4XAQCAu3o49WFXl4DLxMgOAAAwNcIOAAAwNcIOAAAwNebsAAAg5uaYGSM7AADA1Ag7AADA1Ag7AADA1JizAwDwGMzL8UyEHQCAqRBonCs6LPqS24tyi+q2EDtwGQsAAJgaYQcAAJgaYQcAAJgac3YAAG6L+TdwBMIOAJhA+qn0KtsGNB5Qh5XADIJyg6puDKu7OhyFsAMALlBVOPHEYMLojWtUG2hMhjk7AADA1BjZQb3G/46B+oHRG9fwpNGb6tQq7KSnpys9PV2FhYWqqKiwaXvttdccUhgAAIAj2B125s2bp/nz56tnz56KiIiQxWJxRl0AAKCG6uNdjeuS3WFn+fLlWr16te6//35n1AMAAOBQdoeds2fP6oYbbnBGLQCAeo65OXBHdoedhx56SGvXrtXs2bOdUQ8AwM0RaFDf1CjsJCcnW3+uqKjQypUr9fHHH6tLly5q2LChzb7PP/+8YysEAAC4DDUKO3v37rV5361bN0nSgQMHHF4QAACAI9Uo7GzdutXZdQAAADiF3XdQHjt2rEpLSyttP3XqlMaOHeuQogAAABzF7rCzZs0a/fLLL5W2//LLL3r99dcdUhQAAICj1Hg1VklJiQzDkGEYKi0tlZ+fn7WtvLxcH3zwgUJDQ51SJACgbrHiCmZS47ATHBwsi8Uii8Widu3aVWq3WCyaN2+eQ4sDAAC4XDUOO1u3bpVhGLrlllv0r3/9SyEhIdY2Hx8fRUdHKzIy0ilFAgDqt4jWEVW25R3Nq8NK6q9qH+oZVnd11Ec1Djv9+vWTJOXk5Khly5Y8EwsAANQLdt9Bubi4WPv376+03WKxyM/PTy1btpSvr69DigMAmB+jPr+qdvQGtWZ32OnWrVu1ozoNGzbUXXfdpRUrVthMYgYAuBcmIcNT2L30fMOGDWrbtq1Wrlyp7OxsZWdna+XKlbr66qu1du1avfrqq9qyZYtmzZrljHoBAADsYvfIzoIFC7R48WLFx8dbt3Xu3FktWrTQ7NmztWvXLjVu3FiPPfaYnn32WYcWC7ij9FPpVbYNaDygDisBLq26v6NwHp+TPlW2cbmqbtkddvbv36/o6OhK26Ojo61zebp166a8PM+6zgrAfRBAUVdYIVU/2B122rdvr0WLFmnlypXy8bmQWs+dO6dFixapffv2kqTvv/9eYWH8KQNAXfnPt/9xdQl1qi4nNTMKU//ZHXaWLl2q22+/XS1atFCXLl0kXRjtKS8v18aNGyVJ33zzjR555BHHVgoAAFALdoedG264QTk5OXrjjTf09ddfS5LuuOMO3XvvvQoICJAk3X///Y6tEgAAoJbsDjuSFBAQoIkTJzq6FsCtMckTMDcuV5lXrcLO4cOHtXXrVhUWFqqiosKmbc6cOQ4pDAAAwBHsDjsvv/yyJk2apGbNmik8PNzmBoMWi4WwAwAA3IrdYefpp5/WggULNH36dGfUAwAA4FB2h52ff/5Zd9xxhzNqAQBUo7rHO1S3FBvwdHY/LuKOO+7QRx995IxaAAAAHM7ukZ02bdpo9uzZysrKUufOndWwYUOb9ilTpjisOAAwq6puAvjm0TfruBLA/OwOOytXrlSTJk2UkZGhjIwMmzaLxULYAQAAbsXusJOTk+OwL9++fbv+/ve/a8+ePcrLy9OGDRs0YsQIa/uYMWO0Zs0am8/Ex8crLS3N+v7EiROaPHmyUlNT5eXlpVGjRmnx4sVq0qSJw+oEAJiDo++lE3xdsEOPB+eo1X12JOns2bPKyclR69at5e1du8OcOnVKXbt21dixYzVy5MhL7jNo0CCtWrXK+t7X19emffTo0crLy9PmzZt17tw5Pfjgg5owYYLWrl1bq5oAmJujHxJa3aTh6jCh2Hm4OSB+z+6Ucvr0aU2ePNk64vL111+rVatWmjx5sq688krNmDGjxscaPHiwBg8eXO0+vr6+Cg8Pv2Tbl19+qbS0NH322Wfq2bOnJOnFF1/UkCFD9OyzzyoyMrLGtQBAVWobaAC4B7tXY82cOVP/7//9P23btk1+fn7W7XFxcVq/fr1Di5Okbdu2KTQ0VFdffbUmTZqkn376ydqWmZmp4OBga9C5WIeXl5c+/fTTKo9ZVlamkpISmxcAADAnu0d23nnnHa1fv169e/e2uXvyNddco6NHjzq0uEGDBmnkyJGKiYnR0aNH9cQTT2jw4MHKzMxUgwYNlJ+fr9DQUJvPeHt7KyQkRPn5+VUeNyUlRfPmzXNorQCAuuNz0qfKttM6XYeV1B3mB9We3WHnhx9+qBQwpAvzb34bfhzh7rvvtv7cuXNndenSRa1bt9a2bds0YID919YvmjlzppKTk63vS0pKFBUVdVm1AgAA92R32OnZs6fef/99TZ48WZKsAeeVV15RbGysY6v7nVatWqlZs2Y6cuSIBgwYoPDwcBUWFtrsc/78eZ04caLKeT7ShXlAv5/oDADMzQHMye6ws3DhQg0ePFgHDx7U+fPntXjxYh08eFA7d+6sdN8dR/vuu+/0008/KSLiwiqG2NhYFRUVac+ePerRo4ckacuWLaqoqFCvXr2cWguA+qmqm/nBPVW5siqsbuvwNGa7ZGb3BOW+ffsqOztb58+fV+fOnfXRRx8pNDRUmZmZ1sBRUydPnlR2drays7MlXbiHT3Z2tnJzc3Xy5Ek9/vjjysrK0n//+1+lp6dr+PDhatOmjeLj4yVJHTp00KBBgzR+/Hjt2rVLO3bsUFJSku6++25WYgEAAEm1vM9O69at9fLLL9tsKyws1MKFC/XEE0/U+Di7d+/WzTffbH1/cR5NQkKCli1bpn379mnNmjUqKipSZGSkBg4cqKeeesrmEtQbb7yhpKQkDRgwwHpTwSVLltTmtAAAl6mqkRifsKonFFfH0ZONqxuxKPqsyKHfVRt1OaJittGb6tT6poK/l5eXp9mzZ9sVdvr37y/DMKps//DDD//wGCEhIdxAEIBDVHWjv7yjeXVciXvjpn2obxwWdgAA5kGgcS5PGlVxB3bP2QEAAKhPGNkBAA/F6A0cyZ1Hq2ocdn57E75L+eGHHy67GAAAAEercdjZu3fvH+5z0003XVYxAAAAjlbjsLN161Zn1gEAAOAUzNkBYDrcJdlWVQ/NrA8PzHTneSCoPwg7HiL9VHqVbQMa1/6hqnWhutphfrV5XlVV98txhuq+qzb356ntpOHa3rQP8AQsPQcAAKbGyA4Al/PEp43X50tLqD+4DHgBIzsAAMDUajWyU1RUpF27dqmwsFAVFRU2bQ888IBDCgPgOLWZ9+TouVxmHb2paoRG+oP5N2FOKAbAJdkddlJTUzV69GidPHlSgYGBslgs1jaLxULYAXBJjp7IW5cILUD9ZnfYeeyxxzR27FgtXLhQ/v7+zqgJdayq//W7+yqt6tTn1Wf13dyDcx16vNqsTnL0yiR3mUdTl/Mvqvuuos+K6qwOwBHsnrPz/fffa8qUKQQdAABQL9g9shMfH6/du3erVatWzqgHgJuo7Ryb2tzjJjosusq2otyiWtUBABfZHXaGDh2qxx9/XAcPHlTnzp3VsGFDm/bbb7/dYcUBcK66vNNwdRN5YR4sdYY7sjvsjB8/XpI0f/78Sm0Wi0Xl5eWXXxXgItyt+fIRagC4G7vDzu+XmgMAALizy7qp4JkzZxxVBwAAgFPYPbJTXl6uhQsXavny5SooKNDXX3+tVq1aafbs2brqqqs0btw4Z9QJwI1UN6EYANyN3WFnwYIFWrNmjZ555hnr/B1J6tSpk1544QXCDuBEdblCCgDMwu6w8/rrr2vlypUaMGCAJk6caN3etWtXffXVVw4tDvBU7vBoBUZvAJhFrW4q2KZNm0rbKyoqdO7cOYcUBQAA4Ch2j+x07NhR//nPfxQdbfu/vrffflvdu3d3WGEAHIfl4PUH96lxnar6nsdj1H92h505c+YoISFB33//vSoqKvTvf/9bhw4d0uuvv66NGzc6o0ag3qrLZ3TxsEoAuDS7w87w4cOVmpqq+fPnq3HjxpozZ46uvfZapaam6tZbb3VGjQD+T20eignXYZQGcA92h53vvvtON954ozZv3lypLSsrS71793ZIYQAAAI5gd9gZOHCgPvnkE4WEhNhs37Fjh4YOHaqioiJH1QaYmjusuAIAT2B32Ondu7cGDhyorVu3KiAgQJK0fft2DRs2THPnznV0fUC9VpcP2gQAXJrdYeeVV17Rn//8Zw0bNkwffvihdu7cqdtvv11PP/20Hn30UWfUCLg1Ag0AuDe7w46Xl5fWrVunoUOH6pZbbtG+ffuUkpKipKQkZ9SHeqiqFUiOXn1kZkxEBgDHqVHY2bdvX6Vtc+fO1T333KP77rtPN910k3WfLl26OLZCAACAy1CjsNOtWzdZLBYZhmHddvH9ihUrtHLlShmGIYvFovLycqcVC5gJozeor1hSj/qmRmEnJyfH2XWgnqnuZnn4VXV3Lj6t03VYCQB4rhqFnd8/GgLAr2r7KIbq/nfM7ekBwHHsnqAsSUePHtULL7ygL7/8UtKF52U9+uijat26tUOLAwAAuFx2h50PP/xQt99+u7p166Y+ffpIunBDwWuuuYZHRsDUqlpi7iMesgkA7szusDNjxgxNmzZNixYtqrR9+vTphB0AAOBW7A47X375pd58881K28eOHasXXnjBETUBbqm2c3PgPKwKAlATXvZ+oHnz5srOzq60PTs7W6GhoY6oCQAAwGFqPLIzf/58/eUvf9H48eM1YcIEffPNN7rhhhskXZiz87e//U3JyclOKxQAAKA2ahx25s2bp4kTJ2r27NkKCAjQc889p5kzZ0qSIiMjNXfuXE2ZMsVphQJ14dtvv3V1CXBDXC4D6rcah52Ld0+2WCyaNm2apk2bptLSUkmyPv0cqO/yT+a7ugQAgIPZNUHZYrHYvCfkAAAAd2dX2GnXrl2lwPN7J06cuKyCAAAAHMmusDNv3jwFBfHwwrpQ1bOnBjQeUMeV1E/Vzb1JPZpa9QfDnFBMLVQ1R4THSACA/ewKO3fffTfLy1Fr1T08tLoQx6RhAPZgQjl+r8Zh548uXwH1xX9yL/3YB0kKDguuu0IAAHWixjcVvLgaCwAAoD6p8chORUWFM+uAA1R3mcjdpaZWM4+mdd3VAQAwH7ufjQXXqs+Bprq5N83VvA4rAQB4EsIO6jVuAggA+CN2PwgUAACgPnFp2Nm+fbuGDRumyMhIWSwWvfPOOzbthmFozpw5ioiIUKNGjRQXF6fDhw/b7HPixAmNHj1agYGBCg4O1rhx43Ty5Mk6PAsAAODOXHoZ69SpU+ratavGjh2rkSNHVmp/5plntGTJEq1Zs0YxMTGaPXu24uPjdfDgQfn5+UmSRo8erby8PG3evFnnzp3Tgw8+qAkTJmjt2rV1fTr4P+5+XxzuwQEAnsWlYWfw4MEaPHjwJdsMw9ALL7ygWbNmafjw4ZKk119/XWFhYXrnnXd0991368svv1RaWpo+++wz9ezZU5L04osvasiQIXr22WcVGRl5yWOXlZWprKzM+r6kpMTBZ2YO1a2Q+qH1D3VYCS6qLqhxd2XAOfgPUv3ntnN2cnJylJ+fr7i4OOu2oKAg9erVS5mZmZKkzMxMBQcHW4OOJMXFxcnLy0uffvpplcdOSUlRUFCQ9RUVFeW8EwEAAC7ltmEnP//CKpuwMNuHFYWFhVnb8vPzKz2+wtvbWyEhIdZ9LmXmzJkqLi62vo4dO+bg6gEAgLvwyKXnvr6+8vX1dXUZbqOqOTbc+wYwNy7PwFO47chOeHi4JKmgoMBme0FBgbUtPDxchYWFNu3nz5/XiRMnrPsAAADP5rYjOzExMQoPD1d6erq6desm6cJE4k8//VSTJk2SJMXGxqqoqEh79uxRjx49JElbtmxRRUWFevXq5arSXcbdV0HBucz6v3SznheAuuPSsHPy5EkdOXLE+j4nJ0fZ2dkKCQlRy5YtNXXqVD399NNq27atdel5ZGSkRowYIUnq0KGDBg0apPHjx2v58uU6d+6ckpKSdPfdd1e5Equ+M2ugYXUXAMBZXBp2du/erZtvvtn6Pjk5WZKUkJCg1atX669//atOnTqlCRMmqKioSH379lVaWpr1HjuS9MYbbygpKUkDBgyQl5eXRo0apSVLltT5uQAAAPdkMQzDcHURrlZSUqKgoCAVFxcrMDDQocd+7eBrDj0ebPFsLABwf09c/4RTjlvTf7/dds4OPAuhBQDgLIQd1BkCDQDAFdx26TkAAIAjEHYAAICpcRkLDsflKgCAO2FkBwAAmBphBwAAmBqXsVArXKoCANQXjOwAAABTI+wAAABTI+wAAABTI+wAAABTY4IyqsQkZACAGRB2QKgBAJgal7EAAICpEXYAAICpEXYAAICpMWfHQzAvBwDgqRjZAQAApkbYAQAApkbYAQAApkbYAQAApkbYAQAApkbYAQAApkbYAQAApkbYAQAApkbYAQAApkbYAQAApkbYAQAApkbYAQAApkbYAQAApsZTz02EJ5sDAFAZIzsAAMDUCDsAAMDUuIxVz3CpCgAA+zCyAwAATI2wAwAATI2wAwAATI2wAwAATI0Jym6KicgAADgGIzsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDU3DrszJ07VxaLxebVvn17a/uZM2eUmJiopk2bqkmTJho1apQKCgpcWLF98k/mV/kCAACO4dZhR5KuueYa5eXlWV+ffPKJtW3atGlKTU3VW2+9pYyMDB0/flwjR450YbUAAMDdeLu6gD/i7e2t8PDwStuLi4v16quvau3atbrlllskSatWrVKHDh2UlZWl3r1713WpAADADbn9yM7hw4cVGRmpVq1aafTo0crNzZUk7dmzR+fOnVNcXJx13/bt26tly5bKzMys9phlZWUqKSmxeQEAAHNy67DTq1cvrV69WmlpaVq2bJlycnJ04403qrS0VPn5+fLx8VFwcLDNZ8LCwpSfX/2cl5SUFAUFBVlfUVFRTjwLAADgSm59GWvw4MHWn7t06aJevXopOjpab775pho1alTr486cOVPJycnW9yUlJQQeAABMyq1Hdn4vODhY7dq105EjRxQeHq6zZ8+qqKjIZp+CgoJLzvH5LV9fXwUGBtq8AACAOdWrsHPy5EkdPXpUERER6tGjhxo2bKj09HRr+6FDh5Sbm6vY2FgXVgkAANyJW1/G+stf/qJhw4YpOjpax48f15NPPqkGDRronnvuUVBQkMaNG6fk5GSFhIQoMDBQkydPVmxsLCuxAACAlVuHne+++0733HOPfvrpJzVv3lx9+/ZVVlaWmjdvLkn6xz/+IS8vL40aNUplZWWKj4/XSy+95OKqAQCAO3HrsLNu3bpq2/38/LR06VItXbq0jioCAAD1Tb2aswMAAGAvwg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1b1cXYHb5J/NdXQIAAB6NkR0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqpgk7S5cu1VVXXSU/Pz/16tVLu3btcnVJAADADZgi7Kxfv17Jycl68skn9fnnn6tr166Kj49XYWGhq0sDAAAuZoqw8/zzz2v8+PF68MEH1bFjRy1fvlz+/v567bXXXF0aAABwMW9XF3C5zp49qz179mjmzJnWbV5eXoqLi1NmZuYlP1NWVqaysjLr++LiYklSSUmJw+s7c/KMw48JAEB94ox/X397XMMwqt2v3oedH3/8UeXl5QoLC7PZHhYWpq+++uqSn0lJSdG8efMqbY+KinJKjQAAeLKn9JRTj19aWqqgoKAq2+t92KmNmTNnKjk52fq+oqJCJ06cUNOmTWWxWJz2vSUlJYqKitKxY8cUGBjotO+pD+iLX9EXv6IvbNEfv6IvfkVf/MowDJWWlioyMrLa/ep92GnWrJkaNGiggoICm+0FBQUKDw+/5Gd8fX3l6+trsy04ONhZJVYSGBjo8X9BL6IvfkVf/Iq+sEV//Iq++BV9cUF1IzoX1fsJyj4+PurRo4fS09Ot2yoqKpSenq7Y2FgXVgYAANxBvR/ZkaTk5GQlJCSoZ8+euv766/XCCy/o1KlTevDBB11dGgAAcDFThJ277rpLP/zwg+bMmaP8/Hx169ZNaWlplSYtu5qvr6+efPLJSpfQPBF98Sv64lf0hS3641f0xa/oC/tZjD9arwUAAFCP1fs5OwAAANUh7AAAAFMj7AAAAFMj7AAAAFMj7NSRpUuX6qqrrpKfn5969eqlXbt2ubqkOrF9+3YNGzZMkZGRslgseuedd2zaDcPQnDlzFBERoUaNGikuLk6HDx92TbFOlJKSouuuu04BAQEKDQ3ViBEjdOjQIZt9zpw5o8TERDVt2lRNmjTRqFGjKt0s0yyWLVumLl26WG+KFhsbq02bNlnbPakvfm/RokWyWCyaOnWqdZun9MfcuXNlsVhsXu3bt7e2e0o//Nb333+v++67T02bNlWjRo3UuXNn7d6929ruKb9DLxdhpw6sX79eycnJevLJJ/X555+ra9euio+PV2FhoatLc7pTp06pa9euWrp06SXbn3nmGS1ZskTLly/Xp59+qsaNGys+Pl5nzpjrAaoZGRlKTExUVlaWNm/erHPnzmngwIE6deqUdZ9p06YpNTVVb731ljIyMnT8+HGNHDnShVU7T4sWLbRo0SLt2bNHu3fv1i233KLhw4friy++kORZffFbn332mVasWKEuXbrYbPek/rjmmmuUl5dnfX3yySfWNk/qB0n6+eef1adPHzVs2FCbNm3SwYMH9dxzz+mKK66w7uMpv0MvmwGnu/76643ExETr+/LyciMyMtJISUlxYVV1T5KxYcMG6/uKigojPDzc+Pvf/27dVlRUZPj6+hr//Oc/XVBh3SksLDQkGRkZGYZhXDjvhg0bGm+99ZZ1ny+//NKQZGRmZrqqzDp1xRVXGK+88orH9kVpaanRtm1bY/PmzUa/fv2MRx991DAMz/q78eSTTxpdu3a9ZJsn9cNF06dPN/r27Vtluyf/DrUXIztOdvbsWe3Zs0dxcXHWbV5eXoqLi1NmZqYLK3O9nJwc5efn2/RNUFCQevXqZfq+KS4uliSFhIRIkvbs2aNz587Z9EX79u3VsmVL0/dFeXm51q1bp1OnTik2NtZj+yIxMVFDhw61OW/J8/5uHD58WJGRkWrVqpVGjx6t3NxcSZ7XD5L03nvvqWfPnrrjjjsUGhqq7t276+WXX7a2e/LvUHsRdpzsxx9/VHl5eaW7OYeFhSk/P99FVbmHi+fvaX1TUVGhqVOnqk+fPurUqZOkC33h4+NT6YG0Zu6L/fv3q0mTJvL19dXEiRO1YcMGdezY0SP7Yt26dfr888+VkpJSqc2T+qNXr15avXq10tLStGzZMuXk5OjGG29UaWmpR/XDRd98842WLVumtm3b6sMPP9SkSZM0ZcoUrVmzRpLn/g6tDVM8LgKoTxITE3XgwAGbuQie6Oqrr1Z2draKi4v19ttvKyEhQRkZGa4uq84dO3ZMjz76qDZv3iw/Pz9Xl+NSgwcPtv7cpUsX9erVS9HR0XrzzTfVqFEjF1bmGhUVFerZs6cWLlwoSerevbsOHDig5cuXKyEhwcXV1S+M7DhZs2bN1KBBg0orBgoKChQeHu6iqtzDxfP3pL5JSkrSxo0btXXrVrVo0cK6PTw8XGfPnlVRUZHN/mbuCx8fH7Vp00Y9evRQSkqKunbtqsWLF3tcX+zZs0eFhYW69tpr5e3tLW9vb2VkZGjJkiXy9vZWWFiYR/XHbwUHB6tdu3Y6cuSIx/29kKSIiAh17NjRZluHDh2sl/Y88XdobRF2nMzHx0c9evRQenq6dVtFRYXS09MVGxvrwspcLyYmRuHh4TZ9U1JSok8//dR0fWMYhpKSkrRhwwZt2bJFMTExNu09evRQw4YNbfri0KFDys3NNV1fVKWiokJlZWUe1xcDBgzQ/v37lZ2dbX317NlTo0ePtv7sSf3xWydPntTRo0cVERHhcX8vJKlPnz6VblHx9ddfKzo6WpJn/Q69bK6eIe0J1q1bZ/j6+hqrV682Dh48aEyYMMEIDg428vPzXV2a05WWlhp79+419u7da0gynn/+eWPv3r3Gt99+axiGYSxatMgIDg423n33XWPfvn3G8OHDjZiYGOOXX35xceWONWnSJCMoKMjYtm2bkZeXZ32dPn3aus/EiRONli1bGlu2bDF2795txMbGGrGxsS6s2nlmzJhhZGRkGDk5Oca+ffuMGTNmGBaLxfjoo48Mw/CsvriU367GMgzP6Y/HHnvM2LZtm5GTk2Ps2LHDiIuLM5o1a2YUFhYahuE5/XDRrl27DG9vb2PBggXG4cOHjTfeeMPw9/c3/vd//9e6j6f8Dr1chJ068uKLLxotW7Y0fHx8jOuvv97IyspydUl1YuvWrYakSq+EhATDMC4snZw9e7YRFhZm+Pr6GgMGDDAOHTrk2qKd4FJ9IMlYtWqVdZ9ffvnFeOSRR4wrrrjC8Pf3N/70pz8ZeXl5rivaicaOHWtER0cbPj4+RvPmzY0BAwZYg45heFZfXMrvw46n9Mddd91lREREGD4+PsaVV15p3HXXXcaRI0es7Z7SD7+VmppqdOrUyfD19TXat29vrFy50qbdU36HXi6LYRiGa8aUAAAAnI85OwAAwNQIOwAAwNQIOwAAwNQIOwAAwNQIOwAAwNQIOwAAwNQIOwAAwNQIOwAAwNQIOwBQh8aMGaMRI0a4ugzAoxB2ANTYmDFjZLFYKr0GDRpU42Ns27ZNFoul0tOrHenll19W165d1aRJEwUHB6t79+5KSUlx2vcBcG/eri4AQP0yaNAgrVq1ymabr6+vw7/n7Nmz8vHxsftzr732mqZOnaolS5aoX79+Kisr0759+3TgwAGH1wigfmBkB4BdfH19FR4ebvO64oorrO0Wi0WvvPKK/vSnP8nf319t27bVe++9J0n673//q5tvvlmSdMUVV8hisWjMmDGSpP79+yspKUlTp05Vs2bNFB8fr7Fjx+q2226z+f5z584pNDRUr7766iXre++993TnnXdq3LhxatOmja655hrdc889WrBggXWfzz77TLfeequaNWumoKAg9evXT59//rnNcSwWi1asWKHbbrtN/v7+6tChgzIzM3XkyBH1799fjRs31g033KCjR49aPzN37lx169ZNK1asUFRUlPz9/XXnnXequLi4yv6sqKhQSkqKYmJi1KhRI3Xt2lVvv/12Df4kANQUYQeAw82bN0933nmn9u3bpyFDhmj06NE6ceKEoqKi9K9//UuSdOjQIeXl5Wnx4sXWz61Zs0Y+Pj7asWOHli9froceekhpaWnKy8uz7rNx40adPn1ad9111yW/Ozw8XFlZWfr222+rrK+0tFQJCQn65JNPlJWVpbZt22rIkCEqLS212e+pp57SAw88oOzsbLVv31733nuvHn74Yc2cOVO7d++WYRhKSkqy+cyRI0f05ptvKjU1VWlpadq7d68eeeSRKmtJSUnR66+/ruXLl+uLL77QtGnTdN999ykjI6PqDgZgHxc/dR1APZKQkGA0aNDAaNy4sc1rwYIF1n0kGbNmzbK+P3nypCHJ2LRpk2EYhrF161ZDkvHzzz/bHLtfv35G9+7dK31nx44djb/97W/W98OGDTPGjBlTZY3Hjx83evfubUgy2rVrZyQkJBjr1683ysvLq/xMeXm5ERAQYKSmplZ5HpmZmYYk49VXX7Vu++c//2n4+flZ3z/55JNGgwYNjO+++866bdOmTYaXl5eRl5dnGMaFPhw+fLhhGIZx5swZw9/f39i5c6dNPePGjTPuueeeKusFYB/m7ACwy80336xly5bZbAsJCbF536VLF+vPjRs3VmBgoAoLC//w2D169Ki07aGHHtLKlSv117/+VQUFBdq0aZO2bNlS5TEiIiKUmZmpAwcOaPv27dq5c6cSEhL0yiuvKC0tTV5eXiooKNCsWbO0bds2FRYWqry8XKdPn1Zubm6V5xEWFiZJ6ty5s822M2fOqKSkRIGBgZKkli1b6sorr7TuExsbq4qKCh06dEjh4eE2xz9y5IhOnz6tW2+91Wb72bNn1b179z/qLgA1RNgBYJfGjRurTZs21e7TsGFDm/cWi0UVFRU1OvbvPfDAA5oxY4YyMzO1c+dOxcTE6MYbb/zDY3Xq1EmdOnXSI488ookTJ+rGG29URkaGbr75ZiUkJOinn37S4sWLFR0dLV9fX8XGxurs2bNVnofFYqlyW03O7VJOnjwpSXr//fdtApLknEnfgKci7ACoUxdXWJWXl9do/6ZNm2rEiBFatWqVMjMz9eCDD9r9nR07dpQknTp1SpK0Y8cOvfTSSxoyZIgk6dixY/rxxx/tPu6l5Obm6vjx44qMjJQkZWVlycvLS1dfffUl6/L19VVubq769evnkO8HUBlhB4BdysrKlJ+fb7PN29tbzZo1q9Hno6OjZbFYtHHjRg0ZMkSNGjVSkyZNqv3MQw89pNtuu03l5eVKSEiodt9JkyYpMjJSt9xyi1q0aKG8vDw9/fTTat68uWJjYyVJbdu21f/8z/+oZ8+eKikp0eOPP65GjRrVqP4/4ufnp4SEBD377LMqKSnRlClTdOedd1a6hCVJAQEB+stf/qJp06apoqJCffv2VXFxsXbs2KHAwMA/PFcANcNqLAB2SUtLU0REhM2rb9++Nf78lVdeqXnz5mnGjBkKCwurtJrpUuLi4hQREaH4+HjriEl1+2ZlZemOO+5Qu3btNGrUKPn5+Sk9PV1NmzaVJL366qv6+eefde211+r+++/XlClTFBoaWuNzqE6bNm00cuRIDRkyRAMHDlSXLl300ksvVbn/U089pdmzZyslJUUdOnTQoEGD9P777ysmJsYh9QCQLIZhGK4uAgCqc/LkSV155ZVatWqVRo4c6epyqjR37ly98847ys7OdnUpAH6Dy1gA3FZFRYV+/PFHPffccwoODtbtt9/u6pIA1EOEHQBuKzc3VzExMWrRooVWr14tb29+ZQGwH5exAACAqTFBGQAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmNr/BzezJ6w14MbeAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples:\n",
      "An Introduction to NVIDIA Cosmos for Physical AI\n",
      "Presentors: None\n",
      "Description: None\n",
      "Summary: The presentation titled \"An Introduction to NVIDIA Cosmos for Physical AI\" focuses on discussing a specific approach for performing Artificial Intelligence in physics. The topic is likely to address a specialized audience, such as researchers or professionals involved in physical AI applications. Key details include the necessary prerequisites, the instruments or technologies involved, and the anticipated outcomes of using this method. No specific details beyond the title are provided.\n",
      "\n",
      "\n",
      "CUTLASS Walkthrough\n",
      "Presentors: Vijay Thakkar\n",
      "Description: Join our walkthrough for everything new in CUTLASS such as Blackwell, Flash Attention 3, and Python Interface. We'll mix lecture portions with hands-on examples.\n",
      "Summary: Vijay Thakkar presents a walkthrough on new CUTLASS features: Blackwell, Flash Attention 3, and a Python interface. This event includes lecture segments and hands-on examples, catering to an audience interested in learning these tools and technologies. No specific prerequisites are mentioned; the outcomes are expected to be the acquisition of knowledge and skills in utilizing the updated CUTLASS.\n",
      "\n",
      "\n",
      "Accelerating Clustering Algorithms to Achieve the Highest Performance\n",
      "Presentors: Allison Ding\n",
      "Description: Clustering is commonly applied across industries for applications such as recommendation systems and fraud detection. In this lab, through examples, we will discuss techniques to accelerate common clustering algorithms and tips/tricks to derive the highest performance.\n",
      "Summary: The presentation by Allison Ding focuses on accelerating clustering algorithms for applications like recommendation systems and fraud detection. It likely covers techniques to enhance performance and includes practical examples, lab setup details, and tools. The audience is not specified, but it's likely researchers, students, or practitioners interested in clustering optimization. Key details preserved: topic (accelerating clustering), potential audience, examples, lab setup, tools/tech, and outcomes (highest performance).\n",
      "\n",
      "\n",
      "“I See Dead Pipelines...Without CI/CD:\" The Gen AI Easy Button for Fine-Tuning, Evaluation, and Inference With NVIDIA NIMs and Nemo Microservices\n",
      "Presentors: Anshul Jindal // Dmitry Mironov // Martin Piercy\n",
      "Description: \"Dead pipelines\" — abandoned scripts that once ran parts of a workflow — plague LLM development, causing errors, delays, and wasted resources. Learn how to automate the entire LLM life cycle using CI/CD pipelines, Kubernetes, NVIDIA NIMs, and Nemo Microservices in a cloud-agnostic approach. Discover how to streamline development, fine-tuning, evaluation, and deployment of LLMs, ensuring seamless integration, validation, and deployment of updates.\n",
      " \n",
      " In this hands-on course, you'll:\n",
      " \n",
      " • Design and build a cloud-agnostic LLMOps CI/CD pipeline on Kubernetes for scalable and flexible Gen AI app deployment\n",
      " • Utilize Argo CD for declarative continuous delivery and Argo Workflows for managing complex LLM workflows\n",
      " • Leverage NVIDIA NIMs and NeMo Microservices in the end-to-end LLMOps pipeline\n",
      " • Learn how to improve development cycles, accuracy, and reliability with automated fine-tuning and continuous evaluation\n",
      "Summary: The presentation focuses on automating the entire Large Language Model (LLM) development lifecycle, from source code to deployment. Key details include the use of Argo CD for continuous delivery and Argo Workflows for complex workflow management, alongside NVIDIA NIMs and NeMo microservices. The outcome aims to improve development cycles, accuracy, and reliability by streamlining fine-tuning, evaluation, and deployment processes in a cloud-agnostic Kubernetes environment. Relevant tools/technologies are highlighted, and the audience includes developers and managers seeking to integrate Gen AI applications into their workflows. Prerequisites are not specified in the given context.\n",
      "\n",
      "\n",
      "Build Your First AI Robotic Arm With OpenVLA and Isaac Sim\n",
      "Presentors: Abubakr Karali // Maycon da Silva Carvalho // Teresa Conceicao\n",
      "Description: Physical AI is transforming many industries. Get a hands-on introduction to creating a simulated robotic arm using OpenVLA, a state-of-the-art, open-source vision-language-action (VLA) model, and NVIDIA Isaac Sim, a high-fidelity simulation platform for robotics. Learn how to set up and integrate these tools to simulate and control a robotic arm. We'll cover the basics of pre-trained VLA models and offer practical guidance on fine-tuning these models for specific tasks using LORA. Then, you'll use IsaacSim to simulate and control a simulated robotic arm. In the end, you'll have the foundation to build and adapt robotic applications in a simulated environment, paving the way for future exploration and development in robotics without the need for costly physical hardware. The workshop is structured like this:\n",
      " \n",
      " 1. Introduction to OpenVLA (20 mins)\n",
      " 2. Lab training fine-tuning (30 mins)\n",
      " 3. IsaacSim (20 min)\n",
      " 4. Lab deploy OpenVLA to IsaacSim (30 mins)\n",
      "Summary: The presentation introduces building a simulated robotic arm using OpenVLA and NVIDIA Isaac Sim. Learn how to set up, integrate, fine-tune VLA models, and deploy them on IsaacSim for a hassle-free robotics simulation. The workshop covers topics like topic (AI robotics simulations), audience (presenters discuss and teach), prerequisites (OpenVLA, IsaacSim, LORA), tools/tech (OpenVLA, IsaacSim, LORA), and outcomes (online training, simulation, and adaptation). No additional facts were added.\n",
      "\n",
      "\n",
      "Build Next-Gen Agents With Large Vision Language Models\n",
      "Presentors: Abubakr Karali // Debraj Sinha // Sammy Ochoa\n",
      "Description: Vision-language models (VLM) are taking computer vision by storm, offering scalability and robust zero-shot solution for countless industries. However, there are many challenges along the way to deploying VLMs. In this workshop, we'll demystify these challenges. You'll learn what VLMs are, and we'll show you how to choose the best model, how to train and fine-tune on a small dataset, and how to deploy and use VLMs scene understanding with NVIDIA Nemo. Then we'll show different workflows for VLM deployment, with NIMs and VIA including grounding the models for more accurate results. \n",
      " \n",
      " The workshop will be structured as follows:\n",
      " 1) Introduction to VLMs (40 mins)\n",
      " a. Families of VLMs \n",
      " b. Choice of the right VLMs\n",
      " c. Training/evaluation\n",
      " d. Fine-tuning\n",
      " e. Where to start\n",
      " 2) Introduction NIMs (10 mins)\n",
      " 3) Hands-on experience with VLM models through NIMs (20 mins)\n",
      " 4) Introduction to VIA (10 mins)\n",
      " 5) Deploy VLM with VIA reference application (20 mins)\n",
      "Summary: The workshop, titled \"Build Next-Gen Agents with Large Vision Language Models,\" involves experts from NVIDIA focusing on deploying and training vision-language models (VLMs) for computer vision tasks. Key topics include selection, training, fine-tuning, and deployment using tools like NVIDIA INference Models (NIMs) and NVIDIA VectorAI (VIA), aiming to provide attendees with practical knowledge for scalable and accurate scene understanding solutions. The workshop is divided into five sessions covering theoretical background, hands-on experience, and practical deployment with NVIDIA tools.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "contexts_with_summaries = [stringify(entry, \"summary\") for entry in raw_entries]\n",
    "contexts_with_descripts = [stringify(entry) for entry in raw_entries]\n",
    "\n",
    "def plot_token_len(entries, color=\"green\", alpha=1, len_fn=token_len):\n",
    "    plt.bar(x=range(len(entries)), height=[len_fn(v) for v in entries], width=1.0, color=color, alpha=alpha)    \n",
    "\n",
    "## Create arrays of the token lengths\n",
    "sorted_summs = [v for _,v in sorted(zip((token_len(x) for x in contexts_with_summaries), contexts_with_summaries))]\n",
    "sorted_origs = [v for _,v in sorted(zip((token_len(x) for x in contexts_with_descripts), contexts_with_descripts))]\n",
    "aligned_summs = [v for _,v in sorted(zip((token_len(x) for x in contexts_with_descripts), contexts_with_summaries))]\n",
    "plot_token_len(sorted_origs, alpha=0.6, color=\"green\")\n",
    "plot_token_len(sorted_summs, alpha=0.6, color=\"grey\")\n",
    "## Lightgreen bars represent the new context length for their respective original green bars\n",
    "plot_token_len(aligned_summs, alpha=0.6, color=\"lightgreen\")\n",
    "plt.xlabel(\"Entry Sample\")\n",
    "plt.ylabel(\"Token Length\")\n",
    "plt.show() \n",
    "\n",
    "print(\"Samples:\")\n",
    "sorted_raw_entries = sorted(raw_entries, key=(lambda v: token_len(str(v.get(\"description\")))))\n",
    "for entry in sorted_raw_entries[:3] + sorted_raw_entries[-3:]:\n",
    "    print(\n",
    "        f\"{entry.get('name')}\"\n",
    "        f\"\\nPresentors: {entry.get('instructors')}\"\n",
    "        f\"\\nDescription: {entry.get('description')}\"\n",
    "        f\"\\nSummary: {entry.get('summary')}\\n\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5978a60-8458-4a65-aa42-d6dd7d2e5e40",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Sounds like a promising direction! Let's implement it in practice and apply this change over all of our entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c094aa2f-3865-4485-bdcd-9ed2bcdf68d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Context Length: 46524\n",
      "New Context Tokens: 8901\n",
      "The following workshops are slated to be presented at NVIDIA's GTC 2025 Conference:\n",
      "\n",
      "Harness NVIDIA’s Advanced Tools for Gen AI in Digital Health\n",
      "Presenters: Jin Li // Katie Link\n",
      "Description: This training lab focuses on NVIDIA's advanced AI tools like NIMs and AI Blueprints, applied in digital health. Presenters: Jin Li and Katie Link. The workshop aims to help participants develop AI-driven solutions for conversing with multimodal healthcare data, enhancing clinician-patient interactions, and analyzing healthcare video content. Key tools include GPU-accelerated large language models (LLMs), advanced techniques like Retrieval Augmented Generation (RAG) and agentic LLM systems, and applications in speech AI and digital human technology. The session emphasizes practical deployment and customization of these technologies for specific digital health scenarios. Prerequisites include basic knowledge of AI and GPU acceleration. Outcomes include hands-on experience with state-of-the-art AI tools tailored for digital health applications.\n",
      "\n",
      "Advanced Medical AI Development with MONAI: From Interactive Annotation to Foundation Models\n",
      "Presenters: Ahmed Harouni\n",
      "Description: This hands-on training lab focuses on advanced medical AI development using MONAI tools. Users will learn to use MONAI Label, VISTA-3D, MAISI, and VILA-M3 to build end-to-end workflows, including AI-assisted annotation, interactive segmentation, synthetic data generation, and advanced visual-language understanding. The presentation provides practical experience with these tools and explains how they work together in real-world medical imaging applications. No prerequisites are mentioned, but this session assumes some familiarity with AI and deep learning concepts.\n",
      "\n",
      "Building Digital Twin Environments With OpenUSD, NVIDIA Isaac Sim, and ROS: A Hands-On Approach to Robotics Simulation\n",
      "Presenters: Ayush Ghosh // Steven Feng\n",
      "Description: The presentation covers building a digital twin environment and simulating rob\n"
     ]
    }
   ],
   "source": [
    "## Construct full context string\n",
    "new_context = \"The following workshops are slated to be presented at NVIDIA's GTC 2025 Conference:\\n\\n\"\n",
    "new_context += \"\\n\\n\".join(contexts_with_summaries)\n",
    "print(\"New Context Length:\", len(new_context))\n",
    "print(f\"New Context Tokens: {token_len(new_context)}\")\n",
    "\n",
    "## Preview context\n",
    "print(new_context[:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beaaeaef-cb92-44ae-8016-8b3b84b9f890",
   "metadata": {},
   "source": [
    "And all of a sudden, we're below our input size threshold! Time to just swap out our context and test it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16e8c76-d2ad-4c08-a516-e16b336a6390",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "## Defined Earlier. Feel free to play around with this\n",
    "\n",
    "## Define an NVIDIA-backed LLM\n",
    "llm = ChatNVIDIA(model=\"meta/llama-3.1-8b-instruct\", base_url=\"http://llm_client:9000/v1\")\n",
    "\n",
    "## Define a structured prompt\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are a helpful instructor assistant for NVIDIA Deep Learning Institute (DLI). \"\n",
    "     \"Assist users with their course-related queries using the provided context. \"\n",
    "     \"Do not reference the 'context' as 'context' explicitly.\"),\n",
    "    (\"user\", \"<context>\\n{context}</context>\"),\n",
    "    (\"ai\", \"Thank you. I will not restart the conversation and will abide by the context.\"),\n",
    "    (\"placeholder\", \"{messages}\")\n",
    "])\n",
    "\n",
    "## Construct the processing pipeline\n",
    "chat_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "## Initialize chatbot state\n",
    "state = {\n",
    "    \"messages\": [(\"ai\", \"Hello! I'm the NVIDIA DLI Chatbot! How can I help you?\")],\n",
    "    \"context\": \"\",  # Empty for now; will be updated later\n",
    "}\n",
    "\n",
    "## Wrap function to integrate AI response generation\n",
    "chat = partial(chat_with_chain, chain=chat_chain)\n",
    "\n",
    "## Defined Earlier\n",
    "#############################################################################\n",
    "\n",
    "state = {\n",
    "    \"messages\": [],\n",
    "    \"context\": new_context,\n",
    "}\n",
    "\n",
    "try:  ## HINT: Consider putting your call logic in the try-catch\n",
    "    chat(state)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400c2d22-53b2-4d30-8c57-6ccbd156f9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Consider saving the material as well, since it will be useful for later\n",
    "## For those who may take this course over multiple sessions, a version is provided.\n",
    "with open(\"simple_long_context.txt\", \"w\") as f:\n",
    "    f.write(new_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f5f6ba-f953-4cac-8ef9-fc63788fcd5e",
   "metadata": {},
   "source": [
    "<hr><br>\n",
    "\n",
    "### **Part 4:** Reflecting On This Exercise\n",
    "\n",
    "This exercise was pretty easy, and did actually lead to an interesting system in some sense. \n",
    "- On a superficial level, all we did was take an overlong context and convert it down to a not-too-overlong context.\n",
    "- Using other terms, we \"canonicalized\" the elements in the global environment into a form that help make up a reasonable \"canonical context\" to our primary LLM.\n",
    "- Pessimistically, we have created a very short-term solution to our limited-context-space multi-turn problem by making the context *a little shorter* than our maximum input length.\n",
    "- Optimistically, we now have a reusable context which can help to keep our entire context within our model's input domain for most single-turn problems (including those that may complement a multi-turn solution).\n",
    "\n",
    "We will continue to use the results of this exercise throughout the coming notebooks, so hopefully the utility of this simple process becomes apparent as we go along!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59451af0-2bb8-430f-9b82-d76793421534",
   "metadata": {},
   "source": [
    "<br>\n",
    "<a href=\"https://www.nvidia.com/en-us/training/\">\n",
    "    <div style=\"width: 55%; background-color: white; margin-top: 50px;\">\n",
    "    <img src=\"https://dli-lms.s3.amazonaws.com/assets/general/nvidia-logo.png\"\n",
    "         width=\"400\"\n",
    "         height=\"186\"\n",
    "         style=\"margin: 0px -25px -5px; width: 300px\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
