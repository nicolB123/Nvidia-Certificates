{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b007233-ee0a-4c5d-8165-4fdba076a8b4",
   "metadata": {},
   "source": [
    "<br>\n",
    "<a href=\"https://www.nvidia.com/en-us/training/\">\n",
    "    <div style=\"width: 55%; background-color: white; margin-top: 50px;\">\n",
    "    <img src=\"https://dli-lms.s3.amazonaws.com/assets/general/nvidia-logo.png\"\n",
    "         width=\"400\"\n",
    "         height=\"186\"\n",
    "         style=\"margin: 0px -25px -5px; width: 300px\"/>\n",
    "</a>\n",
    "<h1 style=\"line-height: 1.4;\"><font color=\"#76b900\"><b>Building Agentic AI Applications with LLMs</h1>\n",
    "<h2><b>Exercise 2:</b> Metadata Generation</h2>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f765c0a-409f-4052-b3ed-7c69cfc477a0",
   "metadata": {},
   "source": [
    "**Welcome to the second exercise!**\n",
    "\n",
    "This is a lean exercise intended to reinforce the concepts of structured output to try and work with course material and even long-form markdown as an exercise medium. Specifically, we will consider how we can generate first realistic metadata, and then an actual jupyter notebook using the tools from our previous section.\n",
    "\n",
    "### **Learning Objectives:**\n",
    "**In this notebook, we will:**\n",
    "\n",
    "- Consider a more involved example of structured output which could be directly applied to synthetic content (*if used responsibly*).\n",
    "- Push beyond the generative priors of your LLM system to improve a longer-form document in an iterative fashion.\n",
    "\n",
    "### **Setup**\n",
    "\n",
    "Before doing this, let's load in our setup from the previous notebook and continue working with it as useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d974c15-ef48-4b64-9006-331a2530f3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_nvidia import ChatNVIDIA\n",
    "from functools import partial\n",
    "\n",
    "from course_utils import chat_with_chain\n",
    "\n",
    "# llm = ChatNVIDIA(model=\"meta/llama-3.1-8b-instruct\", base_url=\"http://llm_client:9000/v1\")\n",
    "llm = ChatNVIDIA(model=\"nvidia/llama-3.1-nemotron-nano-8b-v1\", base_url=\"http://llm_client:9000/v1\")\n",
    "\n",
    "## Minimum Viable Invocation\n",
    "# print(llm.invoke(\"How is it going? 1 sentence response.\").content)\n",
    "\n",
    "## Back-and-forth loop\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "         \"You are a helpful instructor assistant for NVIDIA Deep Learning Institute (DLI). \"\n",
    "         \" Please help to answer user questions about the course. The first message is your context.\"\n",
    "         \" Restart from there, and strongly rely on it as your knowledge base. Do not refer to your 'context' as 'context'.\"\n",
    "    ),\n",
    "    (\"user\", \"<context>\\n{context}</context>\"),\n",
    "    (\"ai\", \"Thank you. I will not restart the conversation and will abide by the context.\"),\n",
    "    (\"placeholder\", \"{messages}\")\n",
    "])\n",
    "\n",
    "## Am LCEL chain to pass into chat_with_generator\n",
    "chat_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "with open(\"simple_long_context.txt\", \"r\") as f:\n",
    "    full_context = f.read()\n",
    "\n",
    "long_context_state = {\n",
    "    \"messages\": [],\n",
    "    \"context\": full_context,\n",
    "}\n",
    "\n",
    "# chat = partial(chat_with_chain, chain=chat_chain)\n",
    "# chat(long_context_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8501c5b-482d-437a-9c8f-7d9840648cb0",
   "metadata": {},
   "source": [
    "<hr><br>\n",
    "\n",
    "### **Part 1:** Generating Simple Metadata\n",
    "\n",
    "In the lecture notebook, we picked up some techniques to generate data simply by asking nicely and enforcing a style. This relied on the model's priors. We noted how every model has some kinds of limitations in this regard. To make things easy, let's start out with an actual productionalizable use-case where even the 8B model shines; **Short-Form Data Extraction**.\n",
    "\n",
    "Our dataset of workshops has a lot of natural-language descriptions and we have a website frontend that requires it to have some sort of a schema, so wouldn't it be great if we could use an LLM to initialize those values?\n",
    "\n",
    "Well, we could define a schema to help us generate these values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c11f050-592f-4edf-87e0-ee3b701f4424",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class MetaCreator(BaseModel):\n",
    "    short_abstract: str = Field(description=(\n",
    "        \"A concise, SEO-optimized summary (1-2 sentences) of the course for students.\"\n",
    "        \" Ensure accuracy and relevance without overstating the workshop's impact.\"\n",
    "    ))\n",
    "    topics_covered: List[str] = Field(description=(\n",
    "        \"A natural-language list of key topics, techniques, and technologies covered.\"\n",
    "        \" Should start with 'This workshop' and follow a structured listing format that lists at least 4 points.\"\n",
    "    ))\n",
    "    abstract_body: str = Field(description=(\n",
    "        \"A detailed expansion of the short abstract, providing more context and information.\"\n",
    "    ))\n",
    "    long_abstract: str = Field(description=(\n",
    "        \"An extended version of the short abstract, followed by the objectives.\"\n",
    "        \" The first paragraph should introduce the topic with a strong hook and highlight its relevance.\"\n",
    "    ))\n",
    "    objectives: List[str] = Field(description=(\n",
    "        \"Key learning outcomes that students will achieve, emphasizing big-picture goals rather than specific notebook content.\"\n",
    "    ))\n",
    "    outline: List[str] = Field(description=(\n",
    "        \"A structured sequence of key topics aligned with major course sections, providing a clear learning path.\"\n",
    "    ))\n",
    "    on_completion: str = Field(description=(\n",
    "        \"A brief summary of what students will be able to accomplish upon completing the workshop.\"\n",
    "    ))\n",
    "    prerequisites: List[str] = Field(description=(\n",
    "        \"Essential prior knowledge and skills expected from students before taking the course.\"\n",
    "    ))\n",
    "\n",
    "def get_schema_hint(schema):\n",
    "    schema = getattr(schema, \"model_json_schema\", lambda: None)() or schema\n",
    "    return ( # PydanticOutputParser(pydantic_object=Obj.model_schema_json()).get_format_instructions()\n",
    "        'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema'\n",
    "        ' {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}},'\n",
    "        ' \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema.'\n",
    "        ' The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n' + str(schema) + '\\n```'\n",
    "    )\n",
    "\n",
    "schema_hint = get_schema_hint(MetaCreator)\n",
    "# schema_hint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9789591-993f-4884-a66c-a215499394bf",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Then, if we just bind our LLM client to abide by the schema, then we should be able to generate it. \n",
    "The code below not only does that, but also shows how one might go about streaming the data or even filtering the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e540b23a-dcb0-489a-907a-515b4cf60f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "short_abstract: This workshop combines Earth-2 artificial intelligence for global weather modeling and neuromash generating K3D scenes in immersive 3D worlds, connecting technical advancements with creative applications. It empowers attendees to apply AI for complex tasks, from weather prediction to immersive experiences for virtual and physical spaces.\n",
      "\n",
      "topics_covered: ['Introduction to AI for Global Weather Modeling (Earth-2)', 'Neural Network Generation of 3D Scenes in Immersive 3D Worlds (NeRF/3DGS)', 'Integration of AI for Geospatial and Geophysical Applications', 'Application of Advanced Computer Vision for Real-World Data Analysis', 'Creative Solutions for 3D Design and Visualization using AI Insights']\n",
      "\n",
      "abstract_body: This workshop merges AI technologies for greenhouse modeling (Earth-2) and generating 3D scenes (NeRF/3DGS), providing students with a comprehensive understanding of how artificial intelligence enhances real-world applications from weather prediction to immersive 3D experiences. By combining these advanced techniques, this course offers a holistic approach to applying AI in high-level tasks such as geospatial and spatial applications. The focus is on using sophisticated computer vision for analyzing and constructing innovative creations in real-world scenarios, making AI more accessible to students receiving critical value from this training.\n",
      "\n",
      "long_abstract: Imagine connecting advanced weather modeling techniques with powerful virtual 3D environments. This workshop introduces participants to Earth-2, a robust AI framework that enables precision science in weather and climate forecasting. It delves deeper into NeRF and 3DGS technologies, transforming how we create 3D motifs for immersive worlds. By integrating these innovations, learners will develop a targeted understanding of applying AI to complex tasks, like climate analysis, while harnessing its power for creative 3D design and visualization.\n",
      "\n",
      "objectives: ['Apply AI tools for global weather modeling to make better-informed predictions and forecasts subjected to natural environmental factors such as humidity, temperature', 'Create advanced weather patterns and geospatial scenes using neural networks and geospatial techniques from Earth-2, generating unique 3D experiences for virtual worlds.', 'Understand the interplay between computational geometry, art, and perception to build immersive 3D success stories.', 'Design and deploy innovative spatial solutions that efficiently adapt to changing global conditions and categories, utilizing AI for a dynamic and adaptive visual experience.']\n",
      "\n",
      "outline: ['Course Introduction: Hi、\\u200bi and Introduction to the Course창 Somebody Get Your Weather Model Ready for Successolucion Maui And Introduction to NERФ and 3DGS', 'Earth-2 Framework for Global Weather Modeling and Real-World AnalyticsTool EMPLOYEER=inputTEd S batchSize Theatre LifeandWhere Advanced -- So__MISERABLE Excellence Illustrates The Process For a Great Visual Experience:', \"Connecting the Dots: Understanding Geospatial Modeling with Enhanced Data Visualization Programming with Aroma and Data Representationto the Future Of Space Terra and Earth, I'm Learning More this Workshop.\"]\n",
      "\n",
      "on_completion: Participate in creating 3D scenes and experiences that can change the way people interact with real-world scenarios.\n",
      "\n",
      "prerequisites: [\"Basic knowledge of computational geometry, as taught in a course such as Cyone Twenty-Three or CC 272, for this article's application. Investing an additional urge: Interest in generating and deploying visual scenes, such as in a course such as Variable Dynamics for 2D algorithms like the Computational Geometry that you learned in lessons of the other elements.\", 'Some familiarity with AI basics through NLP and supportive topics, as found in this sparked Tags - AI, Artificial Intelligence, Computational%% XX is Existing Features like Chat **XC to YAI in literature.) and practices with various occupations acquire in how to apply these kind of notions.']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "structured_llm = llm.with_structured_output(\n",
    "    schema=MetaCreator.model_json_schema(), \n",
    "    strict=True\n",
    ")\n",
    "\n",
    "meta_chain = prompt | structured_llm\n",
    "meta_gen_directive = (\n",
    "    # f\"Can you generate a course entry on the Earth-2 course? {schema_hint}\"\n",
    "    # f\"Can you combine the topics of the Earth-2 course and the NeRF/3DGS courses and generate a compelling course entry? {schema_hint}\"\n",
    "    f\"Can you combine the topics of the Earth-2 course and the NeRF/3DGS courses and generate a compelling course entry? Make sure to explain how they combine. {schema_hint}\"\n",
    ") \n",
    "meta_gen_state = {\n",
    "    \"messages\": [(\"user\", meta_gen_directive)],\n",
    "    \"context\": full_context,\n",
    "}\n",
    "\n",
    "# answer = meta_chain.invoke(meta_gen_state)\n",
    "# print(answer)\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "answer = {}\n",
    "for chunk in meta_chain.stream(meta_gen_state):\n",
    "    clear_output(wait=True)\n",
    "    for key, value in chunk.items():\n",
    "        print(f\"{key}: {value}\", end=\"\\n\\n\", flush=True)\n",
    "        answer[key] = value\n",
    "\n",
    "# llm._client.last_response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149e1ba0-375b-42e3-a987-ceb205097278",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Ok! That's not bad! It's reflective of the same limitations that we discussed in the lecture, but it does seem to be making good use of its context (while not degenerating into nonsense). Maybe we can ask it to improve upon it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a16e8c76-d2ad-4c08-a516-e16b336a6390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "short_abstract: This workshop combines AI for advanced weather forecasting (Earth-2) and creating immersive 3D scenes (NeRF/3DGS) for real-world applications, ensuring students learn how AI can transform complex tasks into innovative solutions.\n",
      "\n",
      "topics_covered: ['This workshop covers:', 'AI for Global Weather Modeling and Geospatial Analysis using Earth-2', 'The Role of Neural Networks in Generating 3D Scenes for Immersive 3D Experiences', 'Computational Geometry for Future Space Exploration and Earth Analytics', 'Innovative Design and Visualization Techniques Utilizing AI Insights']\n",
      "\n",
      "abstract_body: This course merges AI tools for weather modeling and sophisticated 3D scene generation, providing a comprehensive understanding of how advanced AI technologies work for geospatial and spatial applications. By studying these innovations, learners will gain insights into integrating computational geometry with art and perception to build immersive and dynamic experiences.\n",
      "\n",
      "long_abstract: Imagine transforming weather predictions and interactive 3D environments with the guidance of Earth-2 and NeRF/3DGS. This workshop introduces participants to a framework for global weather modeling and real-world geometrical designs, with emphasis on understanding AI's impact on spatial analysis and 3D visualization.\n",
      "\n",
      "objectives: ['Apply Earth-2 for precise climate forecasting with factors like humidity and temperature.', 'Create dynamic weather patterns and customized 3D scenes using neural networks and geospatial tools, optimizing for clarity and creativity.', 'Master the application of computational geometry and perception to design real-world adaptive visual experiences.', 'The course guide emphasizes the blending of AI, computational geometry, and design to achieve paramount visual and experiential outcomes.', 'Some background in computational geometry and an interest in AI applications.', 'Some familiarity with AI fundamentals and a willingness to practice integrating AI tools with geometrical data.', \"on_completion': \"]\n",
      "\n",
      "outline: ['Course Overview: Introduction, AI Foundations for Patience', 'Earth-2 Framework for Global Weather and Geospatial Awareness', 'NeRF and 3DGS for Immersive Stage-Setting', 'Computational Gems for Timeless Custom Visual Development.', 'Punishment: Correction of bounded states.', 'On Completion: Creating Imperative Visual Experiences.', 'Prerequisites']\n",
      "\n",
      "on_completion: Apply advanced AI and computer vision techniques to construct immersive and adaptable 3D experiences.\n",
      "\n",
      "prerequisites: ['Background in computational geometry as delivered by a course such as Cyone Twenty-Three or CC 272.', 'Interest in generating and deploying visual scenes and geometrical examples from allied fields.', 'So some familiarity with AI basics from linear concepts taught in study materials and a willingness to merge AI with geometrical designs.']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## TODO: See if you can prompt-engineer this solution to lead to an improved autoregression.\n",
    "## Prompt-engineered refinement pass: keep it short, schema-aligned, and grounded.\n",
    "## Key idea: remind the model of constraints + ask for targeted edits + forbid adding facts.\n",
    "meta_refine_directive = (\n",
    "    \"You previously generated a draft JSON object that should conform to the provided schema.\\n\\n\"\n",
    "    \"Task: Improve the draft with a *second pass*.\\n\"\n",
    "    \"- Correct factual errors and internal inconsistencies.\\n\"\n",
    "    \"- Replace vague phrasing with concrete, accurate language.\\n\"\n",
    "    \"- Ensure each field satisfies its description (e.g., topics_covered starts with 'This workshop' and lists >= 4 items).\\n\"\n",
    "    \"- Keep claims grounded: do NOT invent prerequisites, tools, datasets, or outcomes not supported by the provided course materials.\\n\"\n",
    "    \"- Keep it marketing-friendly but not hypey (no exaggerated promises).\\n\\n\"\n",
    "    \"Output requirements:\\n\"\n",
    "    \"- Return ONLY a JSON instance that matches the schema (no prose).\\n\"\n",
    "    \"- Keep wording concise; avoid repetition across fields.\\n\"\n",
    ")\n",
    "\n",
    "meta_gen_state = {\n",
    "    \"messages\": [\n",
    "        (\"user\", meta_gen_directive),\n",
    "        (\"ai\", str(answer)),\n",
    "        (\"user\", meta_refine_directive),\n",
    "    ],\n",
    "    ## Give the model enough grounding to correct itself without re-injecting the entire chat history.\n",
    "    \"context\": full_context,\n",
    "}\n",
    "\n",
    "answer2 = {}\n",
    "for chunk in meta_chain.stream(meta_gen_state):\n",
    "    clear_output(wait=True)\n",
    "    for key, value in chunk.items():\n",
    "        print(f\"{key}: {value}\", end=\"\\n\\n\", flush=True)\n",
    "        answer2[key] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15db1b05-f731-4982-954f-5875e7d667ed",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Yeah... it can get better to a point.** \n",
    "- If we incorporate chat history, you'll start running into issues fast as the model starts to reach its context limit.\n",
    "- If we don't, we can still squeeze some customization from the LLM and can reasonably generate a better or longer outline... to a point.\n",
    "\n",
    "For this use-case, this model actually isn't that bad, but for something a bit longer, the limitations clearly start to show..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c83f222-4721-4ed5-8ffe-cf3ec7f31da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pick your preferred option\n",
    "final_answer = answer2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6945e34-1fda-47ed-a09d-692c9defa10c",
   "metadata": {},
   "source": [
    "<hr><br>\n",
    "\n",
    "### **Part 2:** Generating A Notebook\n",
    "\n",
    "We've seen some fuzzy limitations when trying to generate our metadata, so let's see if we start to see more obvious problems when we get more ambitious. Below, we show an attempt at using the GPT-4o model to generate a notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7baec8fb-6f11-484f-a442-ed5bd2f5a0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please generate a starter jupyter notebook notebook for this course. Assume it's a DLI course, please add some amount of interactivity, and make sure to give your output as markdown with code inside ```python ...``` blocks\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, Markdown, Latex\n",
    "with open(\"chats/make_me_a_notebook/input.txt\", \"r\") as f:\n",
    "    notebook_input_full = f.read()\n",
    "    notebook_input_prompt = notebook_input_full.split(\"\\n\\n\")[-1]\n",
    "# print(notebook_input_full)\n",
    "print(notebook_input_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2e21d42-cb10-4f9a-8c1b-228158f109ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### NVIDIA DLI Course: Accelerate AI Weather Models and 3D Visualizations\n",
       "\n",
       "# Introduction\n",
       "\n",
       "This notebook will guide you through the key concepts of NVIDIA Earth-2, Neural Radiance Fields (NeRFs), and 3D Gaussian Splatting. By the end, you'll be able to:\n",
       "- Render complex 3D scenes using NeRFs.\n",
       "- Efficiently render large datasets with 3D Gaussian Splatting.\n",
       "- Use NVIDIA Earth-2 to accelerate AI weather modeling.\n",
       "\n",
       "Let's get started!\n",
       "\n",
       "## 1. Setup Environment\n",
       "\n",
       "```python\n",
       "# Install necessary libraries (uncomment the lines if running locally)\n",
       "# !pip install torch torchvision torchaudio\n",
       "# !pip install numpy matplotlib opencv-python-headless\n",
       "\n",
       "import torch\n",
       "import numpy as np\n",
       "import matplotlib.pyplot as plt\n",
       "import cv2\n",
       "```\n",
       "\n",
       "## 2. Introduction to Neural Radiance Fields (NeRFs)\n",
       "\n",
       "NeRFs enable the synthesis of photorealistic 3D scenes from sparse 2D images by learning a volumetric scene representation.\n",
       "\n",
       "```python\n",
       "# Sample code to define a simple NeRF-like function\n",
       "\n",
       "def nerf_function(xyz):\n",
       "    \"\"\"Simple function simulating NeRF behavior.\"\"\"\n",
       "    return np.exp(-np.linalg.norm(xyz, axis=-1))\n",
       "\n",
       "# Generate a sample 3D coordinate grid\n",
       "xyz = np.random.rand(100, 3) * 2 - 1  # Values between -1 and 1\n",
       "nerf_values = nerf_function(xyz)\n",
       "\n",
       "# Visualizing the NeRF function output\n",
       "plt.scatter(xyz[:, 0], xyz[:, 1], c=nerf_values, cmap='viridis')\n",
       "plt.colorbar(label='Intensity')\n",
       "plt.xlabel('X-axis')\n",
       "plt.ylabel('Y-axis')\n",
       "plt.title('NeRF Function Output')\n",
       "plt.show()\n",
       "```\n",
       "\n",
       "## 3. Introduction to 3D Gaussian Splatting\n",
       "\n",
       "3D Gaussian Splatting allows efficient rendering of large point cloud datasets, commonly used for weather and environmental simulations.\n",
       "\n",
       "```python\n",
       "# Simulating 3D Gaussian Splatting\n",
       "\n",
       "def gaussian_splatting(points, sigma=0.1):\n",
       "    \"\"\"Apply Gaussian smoothing to a 3D point cloud.\"\"\"\n",
       "    return np.exp(-np.linalg.norm(points, axis=-1) / (2 * sigma**2))\n",
       "\n",
       "# Generating a synthetic 3D point cloud\n",
       "points = np.random.randn(500, 3) * 0.5\n",
       "splat_values = gaussian_splatting(points)\n",
       "\n",
       "# Visualizing the Gaussian splatting effect\n",
       "fig = plt.figure(figsize=(6, 6))\n",
       "ax = fig.add_subplot(111, projection='3d')\n",
       "ax.scatter(points[:, 0], points[:, 1], points[:, 2], c=splat_values, cmap='coolwarm')\n",
       "ax.set_title('3D Gaussian Splatting')\n",
       "plt.show()\n",
       "```\n",
       "\n",
       "## 4. Using NVIDIA Earth-2 for AI Weather Modeling\n",
       "\n",
       "NVIDIA Earth-2 provides acceleration for AI weather models. Below is an interactive example where you can modify weather parameters.\n",
       "\n",
       "```python\n",
       "# Simulating a simplified AI weather model\n",
       "from ipywidgets import interact\n",
       "\n",
       "def simple_weather_model(temperature, humidity, wind_speed):\n",
       "    \"\"\"A basic model for simulating temperature impact on climate.\"\"\"\n",
       "    return temperature * 0.5 + humidity * 0.3 + wind_speed * 0.2\n",
       "\n",
       "interact(simple_weather_model, temperature=(0, 50, 5), humidity=(0, 100, 10), wind_speed=(0, 50, 5));\n",
       "```\n",
       "\n",
       "## 5. Real-World Applications\n",
       "\n",
       "Case studies will be covered in the workshop, but here’s an example of how these methods can be applied in climate simulations.\n",
       "\n",
       "```python\n",
       "# Combining NeRFs, Gaussian Splatting, and AI weather models\n",
       "\n",
       "def combined_model(xyz, temp, humidity, wind):\n",
       "    \"\"\"Simulates a weather model integrating NeRFs and Gaussian Splatting.\"\"\"\n",
       "    nerf_effect = nerf_function(xyz)\n",
       "    splatting_effect = gaussian_splatting(xyz)\n",
       "    weather_effect = simple_weather_model(temp, humidity, wind)\n",
       "    return nerf_effect * splatting_effect * weather_effect\n",
       "\n",
       "# Sample combined simulation\n",
       "xyz_sample = np.random.rand(200, 3) * 2 - 1\n",
       "weather_output = combined_model(xyz_sample, temp=30, humidity=60, wind=15)\n",
       "\n",
       "# Visualization\n",
       "plt.scatter(xyz_sample[:, 0], xyz_sample[:, 1], c=weather_output, cmap='plasma')\n",
       "plt.colorbar(label='Simulation Output')\n",
       "plt.xlabel('X-axis')\n",
       "plt.ylabel('Y-axis')\n",
       "plt.title('Combined AI Weather Model Output')\n",
       "plt.show()\n",
       "```\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "In this notebook, we explored:\n",
       "- NeRFs for rendering 3D scenes.\n",
       "- 3D Gaussian Splatting for efficient large dataset visualization.\n",
       "- NVIDIA Earth-2’s role in AI weather modeling.\n",
       "\n",
       "Continue exploring these topics and apply them to real-world weather simulations!\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<hr><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# !cat chats/make_me_a_notebook/output.txt\n",
    "display(Markdown(\"chats/make_me_a_notebook/output.txt\"))\n",
    "display(Markdown(\"<hr><br><br>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa761a6-60b2-43b5-ad1a-673f8a8185c1",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "The notebook output in [`chats/make_me_a_notebook/output.txt`](./chats/make_me_a_notebook/output.txt) is the first-attempt output that came out of GPT-4o when I asked it to generate a notebook per [`chats/make_me_a_notebook/input.txt`](./chats/make_me_a_notebook/input.txt). It's serviceable enough with such a vague input, and can be improved **to some point** by just asking it for better output, criticizing it, and giving it enough information to work with. \n",
    "\n",
    "The common anecdote \"garbage in, garbage out\" comes to mind, since the LLM is just mirroring the style of reasonable output given your input specific input. But due to the conversational nature of the training (not helped by the chat prompts into which the messages are being funneled), your output will usually be uncomfortably short and just imprecise enough for many advanced use cases.\n",
    "\n",
    "Still, let's see if we can improve on this output by giving our LLM a style reference and asking it to rephrase the notebook a bit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dca0c15a-9cde-46bb-9f82-88c919f4f17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "[Human]: Can you please construct a good notebook in markdown format?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Agent]: Certainly! Here's a basic structure for a markdown note taking display, which you can adapt to your needs. I've included some example markdown for headers, lists, and footnotes for clarity.\n",
      "\n",
      "```markdown\n",
      "# Your DiscoverNotes\n",
      "\n",
      "## My Notes\n",
      "\n",
      "### **My Sources**\n",
      "* [header]\n",
      "* [header]\n",
      "* ...\n",
      "\n",
      "### **My Explanations**\n",
      "* [explanation]\n",
      "* [explanation]\n",
      "* ...\n",
      "\n",
      "### **My Questions**\n",
      "* [question]\n",
      "* [question]\n",
      "* ...\n",
      "\n",
      "### **My Insights**\n",
      "* [insight]\n",
      "* [insight]\n",
      "* ...\n",
      "\n",
      "### **What I Need to Do**\n",
      "* [task]\n",
      "* [task]\n",
      "* ...\n",
      "\n",
      "### **References**\n",
      "* [source]\n",
      "* [source]\n",
      "* ...\n",
      "\n",
      "### **Summary (if needed)**\n",
      "* [summary] **Brief overview of what I've learned or are thinking about.**\n",
      "\n",
      "## Example Notes\n",
      "\n",
      "| **Header 1** | **Header 2** |\n",
      "| --- | --- |\n",
      "| **Information** | **Data Summary** |\n",
      "| **Details** | **Specific Data** |\n",
      "| **Dates** | **Meeting or Event** |\n",
      "\n",
      "## How to Do it\n",
      "\n",
      "1. **Additive Notes**:\n",
      "   * * Start each note with a brief header.\n",
      "   * * Write your official reason within a paragraph of about 75 words.\n",
      "   * * *Explore markdown for creative expression within your notes.\n",
      "\n",
      "2. **Notes with in Markdown**:\n",
      "   * **Text Boxes**: Before a certain release or feature?\n",
      "   * **Tables of Data**: This can be a great way to summarize.\n",
      "\n",
      "3. **Adding References to the Notes you Need to see Later**\n",
      "   * You can easily link to notes we've taken from the previous notes.\n",
      "   * Note: use `## Note ID: 1234` to reference it.\n",
      "\n",
      "These notes are quite comfortable, as the best relevant knowledge and required steps might need right review, that changes accordingly DOC. To review my examples, we can see especially for: https://stackoverflow.com/questions/26956/how-to-add-which-markup-andHeaderCode to see the definition and characteristics of the markup and header codes it refers to. For more detailed clarification, could you see with (since note) with the following source: YAHOO SEARCH https://www.yahoo.com/search?q=%5E%20\n",
      "```python\n",
      "# Note ID: 1234\n",
      "```\n",
      "Helpful for pre-being able to know what OP operates, as we can run a GIVEN Crosby scheme for 0.5 also trend Info with the [Op's des cription - this text will be replaced using the OpenAI API call function](https://weights_BEFORE proletopers)\n",
      "\n",
      "Please give to know if you require to review one of your previous note, just give the Name. I will have the option to open it and provide my explanations.\n",
      "```\n",
      "\n",
      "Please let me know if this notebook structure meets your expectations or if you would like any adjustments. I'm looking forward to helping you with your note taking needs."
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "[Human]: \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def notebook_to_markdown(path: str) -> str:\n",
    "    \"\"\"Load a Jupyter notebook from a given path and convert it to Markdown format.\"\"\"\n",
    "    with open(path, 'r', encoding='utf-8') as file:\n",
    "        notebook = json.load(file)\n",
    "    markdown_content = []\n",
    "    for cell in notebook['cells']:\n",
    "        if cell['cell_type'] == 'code':          # Combine code into one block\n",
    "            markdown_content += [f'```python\\n{\"\".join(cell[\"source\"])}\\n```']\n",
    "        elif cell['cell_type'] == 'markdown':    # Directly append markdown source\n",
    "            markdown_content += [\"\".join(cell[\"source\"])]\n",
    "        # for output in cell.get('outputs', []):   # Optionally, you can include cell outputs\n",
    "        #     if output['output_type'] == 'stream':\n",
    "        #         markdown_content.append(f'```\\n{\"\".join(output[\"text\"])}\\n```')\n",
    "    return '\\n\\n'.join(markdown_content)\n",
    "\n",
    "notebook_example = notebook_to_markdown(\"extra_utils/general_representative_notebook.ipynb\")\n",
    "\n",
    "context = str(final_answer)\n",
    "# context = (\n",
    "#     f\"THE FOLLOWING IS AN EXAMPLE NOTEBOOK FOR STYLE ONLY: \\n\\n{notebook_example}\"\n",
    "#     \"\\n\\n=========\\n\\n\"\n",
    "#     f\"THE FOLLOWING IS THE TOPIC COURSE THAT WE ARE DISCUSSING:\\n\\n{final_answer}\\n\\n\"\n",
    "# )\n",
    "\n",
    "long_context_state = {\n",
    "    \"messages\": [],\n",
    "    \"context\": context,\n",
    "}\n",
    "\n",
    "chat = partial(chat_with_chain, chain=chat_chain)\n",
    "chat(long_context_state)\n",
    "\n",
    "## EXAMPLE INPUTS ##\n",
    "## Option: Can you please construct a good notebook in markdown format?\n",
    "## Option: That's great, but there is no code. Can you please flesh out each section within an end-to-end narrative?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af20a90b-d1ae-4bf8-aebc-ab19955344f1",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "In our case, our model is quite small and we're also limiting our endpoint to a short input and short output (for its own good), so the amount of content it can generate really is quite limited. This limitation does, however, manifest in all realistic scenarios regardless of the model quality. For any modern LLM:\n",
    "- Though straight decoding of the solution can work for some contexts, they cannot scale up to arbitrarily-large inputs or outputs. \n",
    "- The quality output length is generally shorter than the quality input length when we get to longer sequences. This is enforced during training and enforces good properties for efficient cost of generation and reduction in context accumulation.\n",
    "\n",
    "In other words, **the space of things that can be given to or expected of an LLM $>>$ the space of things that an LLM can actually understand well $>>$ the space of things that the LLM can actually output well.** *($>>$ = \"far greater than\")*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4d2f4b-84bc-44c5-8ac6-cc9fc2fc59e5",
   "metadata": {},
   "source": [
    "Given this insight, we can understand that trying to force the LLM to produce a notebook all at once might lead to incoherence at the global scale. However, it seems to be starting off at least somewhat ok, so maybe there's some merit in the approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d53cca4-01c2-4156-a795-dbd548c9f4e0",
   "metadata": {},
   "source": [
    "<hr><br>\n",
    "\n",
    "### **Part 3:** Using an Agent Canvas\n",
    "\n",
    "When we observe that we can't directly output the thing that we want, the next question is \"can we take in what we want.\" \n",
    "- It seemed like the LLM was able to roughly follow along with the premise when we only gave it the premise as input, but started derailing when we gave it a representative example. \n",
    "- Furthermore, it was likely able to actually improve upon your notebook through conversation, so maybe we can start there.\n",
    "\n",
    "**Canvasing Approach:** Instead of getting the model to predict the full document, get it to treat the document as  an environment and propose one of the following to the LLM:\n",
    "> - ***\"Please propose a modification that will improve the state of the document. Here are your options. Pick one/several and they will be done.\"***\n",
    "> - ***\"Here is the whole state, and you are tasked with improving JUST THIS SUBSECTION OF IT. Please output your update to that section. No other sections will be modified.\"***\n",
    "> - ***\"This is the whole document. This section is bad because of one or more of the following: {criticisms}. Replace it with an improved version.\"***\n",
    "\n",
    "If the model is capable of understanding both the full environment and the instruction, then it can directly autoregress only a small section or even a strategic modification of the output. Combine this approach with structured output or chain of thought, and you're likely to get a formulation that, while not perfect, helps to approach the potential output length towards the potential input length of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d93a1c62-83c5-45e7-8422-f3a6d58d5ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Insert a notebook of choice\n",
    "STARTING_NOTEBOOK = \"\"\"\n",
    "# Draft Notebook\n",
    "\n",
    "### 1. Overview\n",
    "Short overview goes here.\n",
    "\n",
    "### 2. Objectives\n",
    "- Objective A\n",
    "- Objective B\n",
    "\n",
    "### 3. Hands-on (placeholder)\n",
    "\n",
    "### 4. Summary\n",
    "Key takeaways.\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac5a3dde-3fbb-43f5-9060-244c05340dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<SECTION 4: General Guidelines and Best Practices>>> \n",
      "\n",
      "to ensure a high-quality, easy-to-follow structure in our notebooks, I would like to outline some general guidelines and best practices. These are essential for maintaining a neat and well-organized document, especially as the following sections will build on this foundation. \n",
      "\n",
      "*   Structure your notebook by creating separate headings (Heading 1, Heading 2, etc.) to organize your thoughts and ideas. This will help to keep similar concepts and problems grouped together, making it easier to reference information without having to search through multiple pages.\n",
      "*   Use a consistent and clear naming convention for your headings, problems, and solutions. This will improve readability and help other readers quickly understand what you've done and what you're looking for.\n",
      "*   Incorporate images (for figures, diagrams, or graphs) and include them within the respective sections or as a new subsection. Properly label and describe these visual elements to provide context and clarity for readers.\n",
      "*   Provide clear and concise summaries or abstracts for each problem statement and solution. This will help readers quickly grasp the nature of the problem and the approach taken.\n",
      "*   Use a consistent font size, spacing, and line length for better visual presentation and readability. This will make your notebook easier to autoscale as it's not reliant on any external settings.\n",
      "*   Regularly review and update the methodology or approach to ensure it remains relevant and efficient. This is particularly important in dynamic research environments.\n",
      "\n",
      "By following these guidelines, we can create a notebook that is both informative and easy to use, setting a foundation for the subsequent sections to build upon. Some examples of sections that could follow include:  *   Case Studies of Successful Implementation *   Additional Resources and References *   Troubleshooting and Maintenance Tips *   Best Practices for Collaboration and Feedback. However, these will not be discussed here. Make sure to prioritize the design of all content and prepare you for Composer feedback, with questions highlighted in \"Compose Your Chinese Name\".\n",
      "<<SECION 4: General Guidelines and Best Practices>>> \n",
      "\n",
      "################################################################\n",
      "\n",
      "\n",
      "<<<SECTION 4: General Guidelines and Best Practices>>> \n",
      "\n",
      "to ensure a high-quality, easy-to-follow structure in our notebooks, I would like to outline some general guidelines and best practices. These are essential for maintaining a neat and well-organized document, especially as the following sections will build on this foundation. \n",
      "\n",
      "*   Structure your notebook by creating separate headings (Heading 1, Heading 2, etc.) to organize your thoughts and ideas. This will help to keep similar concepts and problems grouped together, making it easier to reference information without having to search through multiple pages.\n",
      "*   Use a consistent and clear naming convention for your headings, problems, and solutions. This will improve readability and help other readers quickly understand what you've done and what you're looking for.\n",
      "*   Incorporate images (for figures, diagrams, or graphs) and include them within the respective sections or as a new subsection. Properly label and describe these visual elements to provide context and clarity for readers.\n",
      "*   Provide clear and concise summaries or abstracts for each problem statement and solution. This will help readers quickly grasp the nature of the problem and the approach taken.\n",
      "*   Use a consistent font size, spacing, and line length for better visual presentation and readability. This will make your notebook easier to autoscale as it's not reliant on any external settings.\n",
      "*   Regularly review and update the methodology or approach to ensure it remains relevant and efficient. This is particularly important in dynamic research environments.\n",
      "\n",
      "By following these guidelines, we can create a notebook that is both informative and easy to use, setting a foundation for the subsequent sections to build upon. Some examples of sections that could follow include:  *   Case Studies of Successful Implementation *   Additional Resources and References *   Troubleshooting and Maintenance Tips *   Best Practices for Collaboration and Feedback. However, these will not be discussed here. Make sure to prioritize the design of all content and prepare you for Composer feedback, with questions highlighted in \"Compose Your Chinese Name\".\n",
      "<<SECION 4: General Guidelines and Best Practices>>> \n",
      "\n",
      "################################################################\n",
      "\n",
      "\n",
      "<<<SECTION 4: General Guidelines and Best Practices>>> \n",
      "\n",
      "to ensure a high-quality, easy-to-follow structure in our notebooks, I would like to outline some general guidelines and best practices. These are essential for maintaining a neat and well-organized document, especially as the following sections will build on this foundation. \n",
      "\n",
      "*   Structure your notebook by creating separate headings (Heading 1, Heading 2, etc.) to organize your thoughts and ideas. This will help to keep similar concepts and problems grouped together, making it easier to reference information without having to search through multiple pages.\n",
      "*   Use a consistent and clear naming convention for your headings, problems, and solutions. This will improve readability and help other readers quickly understand what you've done and what you're looking for.\n",
      "*   Incorporate images (for figures, diagrams, or graphs) and include them within the respective sections or as a new subsection. Properly label and describe these visual elements to provide context and clarity for readers.\n",
      "*   Provide clear and concise summaries or abstracts for each problem statement and solution. This will help readers quickly grasp the nature of the problem and the approach taken.\n",
      "*   Use a consistent font size, spacing, and line length for better visual presentation and readability. This will make your notebook easier to autoscale as it's not reliant on any external settings.\n",
      "*   Regularly review and update the methodology or approach to ensure it remains relevant and efficient. This is particularly important in dynamic research environments.\n",
      "\n",
      "By following these guidelines, we can create a notebook that is both informative and easy to use, setting a foundation for the subsequent sections to build upon. Some examples of sections that could follow include:  *   Case Studies of Successful Implementation *   Additional Resources and References *   Troubleshooting and Maintenance Tips *   Best Practices for Collaboration and Feedback. However, these will not be discussed here. Make sure to prioritize the design of all content and prepare you for Composer feedback, with questions highlighted in \"Compose Your Chinese Name\".\n",
      "<<SECION 4: General Guidelines and Best Practices>>> \n",
      "\n",
      "################################################################\n",
      "\n",
      "\n",
      "<<<SECTION 4: General Guidelines and Best Practices>>> \n",
      "\n",
      "to ensure a high-quality, easy-to-follow structure in our notebooks, I would like to outline some general guidelines and best practices. These are essential for maintaining a neat and well-organized document, especially as the following sections will build on this foundation. \n",
      "\n",
      "*   Structure your notebook by creating separate headings (Heading 1, Heading 2, etc.) to organize your thoughts and ideas. This will help to keep similar concepts and problems grouped together, making it easier to reference information without having to search through multiple pages.\n",
      "*   Use a consistent and clear naming convention for your headings, problems, and solutions. This will improve readability and help other readers quickly understand what you've done and what you're looking for.\n",
      "*   Incorporate images (for figures, diagrams, or graphs) and include them within the respective sections or as a new subsection. Properly label and describe these visual elements to provide context and clarity for readers.\n",
      "*   Provide clear and concise summaries or abstracts for each problem statement and solution. This will help readers quickly grasp the nature of the problem and the approach taken.\n",
      "*   Use a consistent font size, spacing, and line length for better visual presentation and readability. This will make your notebook easier to autoscale as it's not reliant on any external settings.\n",
      "*   Regularly review and update the methodology or approach to ensure it remains relevant and efficient. This is particularly important in dynamic research environments.\n",
      "\n",
      "By following these guidelines, we can create a notebook that is both informative and easy to use, setting a foundation for the subsequent sections to build upon. Some examples of sections that could follow include:  *   Case Studies of Successful Implementation *   Additional Resources and References *   Troubleshooting and Maintenance Tips *   Best Practices for Collaboration and Feedback. However, these will not be discussed here. Make sure to prioritize the design of all content and prepare you for Composer feedback, with questions highlighted in \"Compose Your Chinese Name\".\n",
      "<<SECION 4: General Guidelines and Best Practices>>> \n",
      "\n",
      "################################################################\n",
      "\n",
      "\n",
      "<<<SECTION 4: General Guidelines and Best Practices>>> \n",
      "\n",
      "to ensure a high-quality, easy-to-follow structure in our notebooks, I would like to outline some general guidelines and best practices. These are essential for maintaining a neat and well-organized document, especially as the following sections will build on this foundation. \n",
      "\n",
      "*   Structure your notebook by creating separate headings (Heading 1, Heading 2, etc.) to organize your thoughts and ideas. This will help to keep similar concepts and problems grouped together, making it easier to reference information without having to search through multiple pages.\n",
      "*   Use a consistent and clear naming convention for your headings, problems, and solutions. This will improve readability and help other readers quickly understand what you've done and what you're looking for.\n",
      "*   Incorporate images (for figures, diagrams, or graphs) and include them within the respective sections or as a new subsection. Properly label and describe these visual elements to provide context and clarity for readers.\n",
      "*   Provide clear and concise summaries or abstracts for each problem statement and solution. This will help readers quickly grasp the nature of the problem and the approach taken.\n",
      "*   Use a consistent font size, spacing, and line length for better visual presentation and readability. This will make your notebook easier to autoscale as it's not reliant on any external settings.\n",
      "*   Regularly review and update the methodology or approach to ensure it remains relevant and efficient. This is particularly important in dynamic research environments.\n",
      "\n",
      "By following these guidelines, we can create a notebook that is both informative and easy to use, setting a foundation for the subsequent sections to build upon. Some examples of sections that could follow include:  *   Case Studies of Successful Implementation *   Additional Resources and References *   Troubleshooting and Maintenance Tips *   Best Practices for Collaboration and Feedback. However, these will not be discussed here. Make sure to prioritize the design of all content and prepare you for Composer feedback, with questions highlighted in \"Compose Your Chinese Name\".\n",
      "<<SECION 4: General Guidelines and Best Practices>>> \n",
      "\n",
      "################################################################\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "         \"You are a helpful instructor assistant for NVIDIA Deep Learning Institute (DLI). \"\n",
    "         \" Please help to answer user questions about the course. The first message is your context.\"\n",
    "         \" Restart from there, and strongly rely on it as your knowledge base. Do not refer to your 'context' as 'context'.\"\n",
    "    ),\n",
    "    (\"user\", \"<context>\\n{context}</context>\"),\n",
    "    (\"ai\", \"Thank you. I will not restart the conversation and will abide by the context.\"),\n",
    "    (\"user\", (\n",
    "        \"The following section needs some improvements:\\n\\n<<<SECTION>>>\\n\\n{section}\\n\\n<<</SECTION>>>\\n\\n\"\n",
    "        \"Please propose an upgrade that would improve the overall notebook quality.\"\n",
    "        \" Later sections will follow and will be adapted by other efforts.\"\n",
    "        \" You may only output modifications to the section provided here, no later or earlier sections.\"\n",
    "        \" Follow best style practices, and assume the sections before this one are more enforcing that the latter ones.\"\n",
    "        \" Make sure to number your section, continuing from the previous ones.\"\n",
    "    )),\n",
    "])\n",
    "\n",
    "## An LCEL chain to pass into chat_with_generator\n",
    "sub_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "delimiter = \"###\"  ## TODO: Pick a delimiter that works for your notebook\n",
    "WORKING_NOTEBOOK = STARTING_NOTEBOOK.split(delimiter)\n",
    "output = \"\"\n",
    "for i in range(len(WORKING_NOTEBOOK)):\n",
    "    chunk = WORKING_NOTEBOOK[i]\n",
    "    ## TODO: Knowing that the state needs \"context\" and \"section\" values,\n",
    "    ## can you construct your input state?\n",
    "    chunk_refinement_state = {\n",
    "        \"context\": None,\n",
    "        \"section\": None,\n",
    "    }\n",
    "    for token in sub_chain.stream(chunk_refinement_state):\n",
    "        print(token, end=\"\", flush=True)\n",
    "        output += token\n",
    "    WORKING_NOTEBOOK[i] = output\n",
    "    print(\"\\n\\n\" + \"#\" * 64 + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1337613d-67c9-4b9f-95b5-15e526102846",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<details><summary><b>Solution</b></summary>\n",
    "\n",
    "```python\n",
    "chunk_refinement_state = {\n",
    "    \"context\": \"####\".join(WORKING_NOTEBOOK),\n",
    "    \"section\": chunk,\n",
    "}\n",
    "```\n",
    "    \n",
    "</details>\n",
    "\n",
    "<hr><br>\n",
    "\n",
    "### **Part 4:** Reflecting On This Exercise\n",
    "\n",
    "As we can see, this approach is quite promising in that it's able to extend the output of the model towards a large context with only local modifications. This 8B model was pretty quickly pushed out of its training distribution with this approach, and it also likely started to go pretty aggressively into hallucination mode due to its vague inputs, but a larger model would be able to iterate on this process for much longer and could even have some error-correcting or randomization efforts thrown in to stabilize the process. \n",
    "\n",
    "This technique is also used in the wild to implement features like codebase modification and collaborative document editing (i.e. OpenAI Canvas). Additionally, even minor modifications to this approach can help you implement some surprisingly-effective and efficient solutions:\n",
    "- **Find-Replace Canvas:** Instead of autoregressing the sections of a document, you can generate find-replace pairs. Executing this process on the chunks, you will wind up with a much safer formulation as well as an easier-to-track footprint. This kind of system can be used to implement AI-enabled spell-checkers and other forms or strategic error correction.\n",
    "- **Document Translation:** More generally, this approach can also be used to translate a document, one section at a time, from one format to another. A similar approach to the one above can be used to translate a document from one language to another, with a bit of context injection thrown in to help give the translating model pipeline some style to guide it.\n",
    "\n",
    "Note that while we call this process *\"canvasing,\"* you may also run into the same or similar idea under the term *\"iterative refinement.\"* They are pretty much one-and-the-same, except the latter is much more general and could technically be applied to any LLM-enabled loop that progresses the input into the output over many iterations. Canvasing implies more strongly that you're using the current environment as a playground and can make strategic modifications to improve the state.\n",
    "\n",
    "----\n",
    "\n",
    "In any case, we've now tested out how our little model can actually help us do some surprisingly-interesting things, while also reflecting on the fact that it has clear limitations. This marks the end of our \"simple pipeline\" exercises for this course. In the next section, we will be using the primitives we've picked up to start working with a proper agents framework while sticking to our very-limited but surprisingly-flexible Llama-8B model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd9454b-ce16-4a8e-bc4c-ecc406e4c7b3",
   "metadata": {},
   "source": [
    "<br>\n",
    "<a href=\"https://www.nvidia.com/en-us/training/\">\n",
    "    <div style=\"width: 55%; background-color: white; margin-top: 50px;\">\n",
    "    <img src=\"https://dli-lms.s3.amazonaws.com/assets/general/nvidia-logo.png\"\n",
    "         width=\"400\"\n",
    "         height=\"186\"\n",
    "         style=\"margin: 0px -25px -5px; width: 300px\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
